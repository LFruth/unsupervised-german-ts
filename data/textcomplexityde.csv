,Unnamed: 0,Unnamed: 0.1,Unnamed: 0.1.1,Unnamed: 0.1.1.1,Unnamed: 0.1.1.1.1,Article_ID,Article,Complex,Simplification
0,0,0,0,0,0,1,Seifenblase,"Wegen dieser leichten Vergänglichkeit wurde ,Seifenblase‘ zu einer Metapher für etwas, das zwar anziehend, aber dennoch inhalts- und gehaltlos ist. In der Kunst wird spätestens seit dem Barock die Seifenblase durchgängig ikonographisch als ein Vanitassymbol benutzt und spiegelt sowohl die Schönheit als auch die Flüchtigkeit des menschlichen Lebens wider. Eine Seifenblase entsteht, wenn sich ein dünner Wasserfilm mit Seifenmolekülen vermischt. Infolge des gravitationsbedingten Auslaufens (Drainage) der zwischen den Seifenfilmoberflächen befindlichen Flüssigkeit dünnt eine Seifenblase in ihrem oberen Teil zunehmend aus. Zudem erfolgt im Laufe des Auslaufprozesses eine Anreicherung von Seifenfilm-stabilisierenden Tensidmolekülen im unteren Bereich der Seifenblase, sodass deren obere Region infolge des relativen Mangels von an die Oberfläche adsorbierten Tensidmolekülen zusätzlich destabilisiert wird. Die Schichtdicke der Seifenblase lässt sich beobachten: Spiegelt die Oberfläche in bunten Interferenzfarben, ist die Schichtdicke vergleichbar mit der Wellenlänge des Lichts. Die Erzeugung von Seifenblasen ist möglich, da die Oberfläche einer Flüssigkeit – in diesem Falle des Wassers – eine Oberflächenspannung besitzt, die zu einem elastischen Verhalten der Oberfläche führt.","Weil Seifenblasen nicht lange halten, wurden sie zu einem  sprachlichen Ausdruck für etwas, das anziehend aber inhaltslos ist. In der Kunst wird die Seifenblase spätestens seit dem Barock als Symbol für Vergänglichkeit benutzt. Sie spiegelt sowohl die Schönheit als auch die Flüchtigkeit des menschlichen Lebens wider. Eine Seifenblase entsteht, wenn sich eine kleine Menge von Wasser (auch Wasserfilm genannt) mit einer kleinen Menge Seife mischt. Wegen der Erdanziehungskraft läuft die Flüssigkeit, die sich zwischen den Seifenfilmoberflächen befindet, nach unten (Drainage). Deshalb dünnt eine Seifenblase in ihrem oberen Teil zunehmend aus.  Beim Auslaufen von einer Seifenblase sammeln sich Moleküle, die die Seifenblase stabil machen, im unteren Bereich der Seifenblase. Dadurch sind im oberen Bereich nur noch wenige vorhanden. Dadurch wird die Seifenblase weniger stabil. Die Dicke der Seifenblase lässt sich beobachten: Wenn die Oberfläche in bunten Farben spiegelt, dann ist die Schicht so dick wie die Wellenlänge des Lichts, Die Erzeugung von Seifenblasen ist möglich, weil Flüssigkeiten - in diesem Falle Wasser - eine elastische Oberfläche besitzen."
1,1,1,1,1,7,2,Badekultur,"So schildert der achte Gesang beispielsweise, wie im Hause des Phaiakenkönigs Alkinoos Odysseus von den Haussklaven ein Bad zubereitet wird, bevor er sich an der Tafel seines Gastgebers niederlässt. Vergleichbare Stellen belegen eine sorgfältige Reinigung vor Gebeten und Opfern und die Sitte, dem Gast zunächst Wasser zu reichen, damit er sich seine Hände waschen könne und ihm anschließend ein Bad anzubieten. Ein bestimmtes Bauschema scheint es nicht gegeben zu haben, man findet Räume mit meist 10 bis 22 Wannen oder Sitzwannen sowohl in rechteckiger (zum Beispiel in Olympia) als auch kreisbogenförmiger Anordnung (zum Beispiel in Gortyn, Gela und Megara Hyblaea). Es gibt keine Belege, dass Gymnasia vor der römischen Zeit ihren Nutzern bereits heißes Wasser anboten, obwohl dieses zur Entfernung des Öls und Schmutzes besser geeignet gewesen wäre. Die griechischen Sportstätten mit integrierten Bädern waren allerdings bereits zu diesem Zeitpunkt Begegnungsstätten, in denen man sich stundenlang aufhielt. Der griechische Komödiendichter Aristophanes (um 450 bis 380 v. Chr.) zweifelt in Die Wolken daran, ob die sich in warmen Bädern verweichlichenden Griechen noch über die Manneskraft verfügten, die ihre Vorfahren in der Schlacht bei Marathon erfolgreich sein ließen. Noch rigoroser in ihrer Ablehnung waren die Spartaner, die in ihrer Ablehnung warmer Bäder sich auf ihren mythischen Staatsgründer Lykurg beriefen und in ihnen eine Gefahr für die Kriegsfähigkeit ihres Staates sahen. Außerdem waren bereits zahlreiche Heilquellen bekannt, von denen viele Göttern geweiht waren.","So schildert der achte Besang beispielsweise folgende Szene:  Im Hause des Phaiakenkönigs Alkinoos wird für Odysseus ein Bad zubereitet. Danach lässt er sich an der Tafel seines Gastgebers nieder.  Es gibt Schriften, die erzählen, dass es üblich war, sich vor Gebeten und Opfern gründlich zu waschen. Außerdem gab es eine Tradition, seinem Gast Wasser zum Händewaschen zu geben und ihm anzubieten, ein Bad zu nehmen. Es gab kein bestimmtes Bauschema. Man findet Räume mit 10-22 Wannen oder Sitzwannen. Die Wannen waren rechteckig oder kreisbogen-förmig angeordnet. Es gibt keine Belege, dass in den Sporthallen vor der römischen Zeit heißes Wasser angeboten wurde. Heißes Wasser wäre aber zur Entfernung von Öl und Schmutz besser geeignet gewesen. Die griechischen Sportstätten mit Bädern waren schon damals Orte in denen sich die Menschen begegneten. Außerdem hielten sich die Menschen dort viele Stunden lang auf. Der griechische Komödiendichter Aristophanes (um 450 bis 380 vor Christus) erklärte in ""Die Wolken"", dass die Griechen durch warme Bäder verweichlicht seien. Er zweifelte daran, dass ihre Manneskraft mit denen der Vorfahren in der Schlacht bei Marathon vergleichbar sei.  Die Spartaner lehnten warmer Bäder massiv ab.  Als Grund nannten sie ihren mythischen Staatsgründer Lykurg. Der sah darin eine mögliche Gefahr für die Kriegsfähigkeit ihres Staates.   Zahlreiche Heilquellen waren bekannt. Diese wurden den Göttern geweiht."
2,2,2,2,2,15,3,Fahrradfahren,"Der Ausdruck Fahrradfahren – auch Radfahren oder Radeln, schweizerisch Velofahren – bezeichnet die Fortbewegung auf einem Fahrrad, sei es als Verkehrsmittel im Radverkehr oder als Sportart, die als Freizeitbeschäftigung, zur Erhaltung der Gesundheit oder als sportlicher Wettkampf bis hin zum Leistungssport betrieben wird. Die Französin Barbara Buatois fuhr mit einem vollverkleideten Liegerad am 19. Juli 2009 im US-amerikanischen Romeo eine Strecke von 84,02 km, womit sie als erste Frau eine Strecke von mehr als 80 km in einer Stunde mit einem Liegerad zurücklegte. Der Fahrer hält das System Fahrrad/Fahrer mit kleinen Lenkausschlägen im Gleichgewicht. Generell gilt Fahrradfahren als sehr gesund (Herz- und Kreislauftraining)[3] und gelenkschonend. Untersuchungen unter anderem des ADFC haben ergeben, dass die Haltung auf dem sogenannten Reiserad bei richtiger Rahmengröße und richtigem Sattel die Haltung ist, die der menschlichen Anatomie am stärksten entgegenkommt. Um eine optimale Versorgung der Füße und eine möglichst geringe Belastung der Knie zu erreichen, sollte die Sattelhöhe so eingestellt werden, dass beim Treten der Pedale am tiefsten Punkt das Bein immer noch leicht angewinkelt ist. Als zweitgrößte Belastungszone ist der Kontakt zwischen Gesäß und Sattel anzusehen. Dieser Berührungspunkt kann insbesondere daher problematisch werden, da das menschliche Becken mit seinen Sitzbeinhöckern und dem Schambein (bzw. den Schambeinkufen, auch Schambeinkamm genannt) durch den Kippwinkel des Beckens Auswirkungen auf die Biegung der gesamten Wirbelsäule hat. Somit kann eine falsche Beckenhaltung (z.B. um Missempfindungen aufgrund des Sattels zu vermeiden) zu einer starken Belastung der Wirbelsäule führen. Gleichfalls problematisch wird ein falscher Beckenwinkel auf dem Sattel für den gesamten Beckenbereich, da dieser Bereich stark mit Blut- und Nervenbahnen durchzogen ist, die auf der Innenseite der Oberschenkel liegen und die die unteren Gliedmaße zu versorgen haben. Werden diese Versorgungsbahnen durch ein Aufliegen des Schambeins bzw. der Schambeinkufen / des Schambeinkamms auf dem Sattel längere Zeit eingeengt oder gar gequetscht, können dadurch Schädigungen der entsprechenden Gefäße und Versorgungsbahnen entstehen. Daher ist es notwendig, die Hauptbelastung dieses Kontaktpunktes auf die Sitzhöcker zu bringen und möglichst wenig Druck auf den Bereich der Schambeinkufen, des Damms, der Genitalien und der innenliegenden obersten Teile der Oberschenkel auszuüben. Dabei spielt die Entfernung des Lenkers zum Gesäß des Radfahrers genauso eine wichtige Rolle wie die Lenkerform (Biegung) und die Höhe des Lenkers, der optimalerweise in gleicher Höhe wie die Mitte der Beckenknochen sein sollte. Die Hand sollte die gerade Verlängerung des Unterarms bilden und weder nach oben noch nach unten geknickt werden, um so durch das Handgelenk eine permanente und ungehinderte Blutversorgung der gesamten Hand sicherzustellen. Als grobe Richtlinie sollten die imaginären Verbindungslinien der drei Kontaktpunkte und des Schulterblattes eine Raute darstellen, deren Seiten möglichst etwa gleich lang sein sollten.","Fahrradfahren ist die Fortbewegung auf einem Fahrrad. Man sagt auch Radfahren oder auf schweizerisch Velofahren dazu. Fahrradfahren beschreibt die Verwendung von Fahrrädern im Verkehr und als Sportart. Man kann Fahrradfahren in der Freizeit, zur Erhaltung der Gesundheit oder als Sportart betreiben. Die Französin Barbara Buatois fuhr mit einem Liegerad am 19. Juli 2009 in Romeo (in der USA) 84,02 km weit. Damit war sie die erste Frau, die in einer Stunde mehr als 80 Kilometer mit einem Liegerad gefahren ist. Der Fahrer hält sich mit leichte Lenken im Gleichgewicht. Fahrradfahren gilt als sehr Gesund für das Herz und den Kreislauf. Außerdem schont es die Gelenke. Untersuchungen von dem ADFC zum Beispiel haben gezeigt, dass die beste Haltung beim Fahrradfahren die ist, wenn der Rahmen die richtige Größe hat und der richtige Sattel benutzt wird. Die Haltung ist am besten, wenn sie an den Körperbau der Menschen angepasst ist. Damit die Füße bestmöglich versorgt und die Knie nur wenig belastet werden, sollte man den Sattel richtig einstellen. Am besten ist es, wenn das Bein beim Treten der Pedale nie ganz gestreckt wird. Auch am tiefsten Punkt sollte das Bein also immer noch leicht angewinkelt werden.  Neben den Füßen wird beim Radfahren auch das Gesäß belastet. Das menschliche Becken besitzt Sitzbeinhöcker und Schambein bzw. Schambeinkufen (auch Schambeinkamm genannt), die beim Fahrradfahren gekippt werden. Dieser Kippwinkel hat Auswirkungen auf die Biegung der gesamten Wirbelsäule. Deshalb kann dieser Berührungspunkt problematisch sein. Dadurch kann eine falsche Haltung vom Becken zu einer starken Belastung der Wirbelsäule führen. Genauso problematisch ist ein falscher Winkel von dem Becken auf dem Sattel für den gesamten Beckenbereich.  Dieser Bereich ist stark mit Blut- und Nervenbahnen durchzogen. Diese liegen auf der Innenseite der Oberschenkel und versorgen die unteren Gliedmaßen. Wenn man falsch auf dem Sattel sitzt, werden einige Versorgungsbahnen im Körper eingeengt oder gequetscht. Damit können diese Versorgungsbahnen und Gefäße geschädigt werden. Deshalb ist es wichtig, so auf dem Sattel zu sitzen, dass wenig Druck ist auf den Schambeinkufen (einem Knochen im unteren Bereich der Hüfte), dem Damm, den Geschlechtsteile und den Oberschenkeln. Wichtig ist der Abstand zwischen Lenker und Gesäß, die richtige Lenkerform (Biegung) und dass die Höhe des Lenkers richtig eingestellt ist. Am besten sollte der Lenker genau auf der Höhe der Mitte der Beckenknochen sein. Die Hand sollte gerade zum Unterarm sein und nicht nach oben oder unten geknickt werden. So kann die gesamte Hand mit Blut versorgt werden. Als grobe Richtlinie sollten die gedachten Verbindungslinien der drei Kontaktpunkte und des Schulterblattes eine Raute darstellen. Deren Seiten sollten möglichst gleich lang sein."
3,3,3,3,3,30,4,Geldautomat,"Eine Unterteilung wird gleichfalls nach standortbedingter Bauform vorgenommen. Weitergehende Sicherungsmaßnahmen können eine Videoüberwachung und eine Zugangskontrolle durch einen Türöffner sein, denn viele GAA befinden sich in Vorräumen der Geschäftsstellen der Banken, sodass sie auch außerhalb der Schalteröffnungszeiten zugänglich sind. Die Softwareausstattung besteht aus einem üblichen Betriebssystem wie beispielsweise Windows XP, Gerätetreibern, einer Kommunikationsschicht (z.B. CEN/XFS oder J/XFS) und einer Anwendung, die den Geldautomaten steuert und die Kommunikation mit der Gegenstelle (Server/Host) organisiert. Für den barrierefreien Zugang verfügen einige GAA über größere Tasten und Displays sowie über einen Kopfhöreranschluss oder Lautsprecher zur Sprachausgabe, um Menschen mit einer Sehbehinderung die Bedienung zu erleichtern oder überhaupt erst möglich zu machen. Bei einigen Automaten wurde die Greifhöhe abgesenkt; Tastatur und Ein/Ausgabe-Schächte befinden sich in einem geringeren Abstand zum Boden als bei Standardgeräten.","Die Bezeichnung richtet sich nach dem Standort und der Bauform. Viele Geldautomaten befinden sich bei Banken im Vorraum. So können sie auch genutzt werden, wenn die Bankschalter geschlossen sind.  Um es dort sicherer zu machen, gibt es Videoüberwachung und eine Kontrolle durch einen Türöffner. Die Softwareausstattung besteht aus einem normalen Betriebssystem, einer Kommunikationsebene und einer Anwendungsebene. Für den barrierefreien Zugang verfügen einige Automaten über große Tasten und Displays. Sie verfügen auch über einen Kopfhöreranschluss oder Lautsprecher zur Sprachausgabe. Dadurch ist es möglich, dass Menschen mit einer Sehbehinderung den Automaten bedienen können.  Einige Automaten wurden niedriger angebracht. Die Tastatur und alle anderen Elemente und sind jetzt besser erreichbar als normale Bankautomaten."
4,4,4,4,4,35,5,Schallplatte,"Der seit dem Produktionsende der Grammophonplatten wesentlich geläufigere Begriff Schellackplatte grenzt diesen älteren Tonträger deutlich von der späteren Schallplatte aus Polyvinylchlorid ab. Die Signale sind in einer vom Rand der Platte spiralförmig nach innen verlaufenden Rille gespeichert, deren Flanken die Schallschwingung des gespeicherten Signals abbilden. Bei der Wiedergabe wird die Abtastspitze eines Tonabnehmers entsprechend ausgelenkt. Die Rückverwandlung in hörbare Schallsignale kann rein mechanisch über eine Membran und einen Schalltrichter oder – bei heute üblichen Plattenspielern – auf elektromechanischem Weg mit anschließender elektronischer Verstärkung erfolgen. Ihm gelang es 1860, das französische Kinderlied Au clair de la lune mit Hilfe eines großen Trichters einzufangen und mit einer Membran, die die Schwingungen auf eine Schweineborste übertrug, auf eine rußgeschwärzte Walze zu kratzen. Die Töne wurden zunächst in eine Zinnfolie geritzt, später auf einer Phonographenwalze mit wendelförmiger Tonspur in Höhenschrift gespeichert, wobei das Prinzip der Amplitudenauslenkung auch hier unmittelbar akustisch (Membran/Trichter) genutzt wurde. Bereits im Jahre 1880 machte der US-amerikanische Physiker Charles Sumner Tainter (Columbia Graphophone Company) die Entdeckung, dass viele technische Nachteile der Edisonischen Walzen (umständliche Handhabung und aufwändige Vervielfältigung) beseitigt werden könnten, wenn man die Tonspur spiralförmig in die Oberfläche einer flachen, runden Scheibe eingraviert. Als Geschäftsmann sah auch er in der umständlichen – und damit teuren – Vervielfältigung der Walzen den entscheidenden Schwachpunkt des Phonographen und verwendete seine Zeit und Mühe vorrangig auf die Lösung dieses Problems. Er konstruierte ein Gerät, das die Schallwellen nicht wie bei Edisons Höhenschrift-Phonographen in vertikaler, durch Auf-und-ab-Bewegung des Schneidstichels entstehender Modulation speicherte, sondern die Rille horizontal auslenkte; die mechanischen Schwingungen ließ er eine Stahlnadel schneckenförmig in eine dick mit Ruß überzogene Glasplatte einritzen. Nach chemischer Härtung des Rußes war er in der Lage, auf galvanoplastischem Wege ein Zink-Positiv und von diesem ein Negativ der Platte anzufertigen, das als Stempel zur Pressung beliebig vieler Positive genutzt werden konnte – die Schallplatte war erfunden. In den folgenden Monaten entwickelte Berliner in Zusammenarbeit mit dem Techniker Werner Suess sein Verfahren weiter, indem er das rußbeschichtete Glas durch eine mit Wachs überzogene Zink- oder Kupferplatte ersetzte. Nach der Gravur der Schallrille in die Wachsschicht wurde die Platte einem Säurebad ausgesetzt, das die noch mit Wachs bedeckten Teile der Platte nicht angriff, die freigelegten Rillen aber in das Metall einätzte, so dass nach Entfernung des Wachses eine haltbare metallene Urplatte entstand, die zur Herstellung der Pressmatrizen verwendet werden konnte. Der zeittypischen Vorliebe für Gräzismen folgend nannte er es Grammophon (sinngemäß: „geschriebener Laut“). Zunächst verwendete er als Pressmasse Zelluloid, das er unmittelbar vom Erfinder dieses Werkstoffs, John W. Hyatt, bezog und das sich bald als technisch ungeeignet erwies. Im Juli 1889 kam Berliner aufgrund materialkundlicher Versuche zu dem Schluss, dass vulkanisiertes Hartgummi als Pressmaterial die günstigsten Eigenschaften aufweise, und erachtete seine Erfindung für ausgereift genug, um den Beginn der Serienproduktion einzuleiten.","Zum Produktionsende des Grammophons wurden die Tonträger Schellackplatten genannt.  Damit wird die Bezeichnung der Schallplatten aus Polyvinylchlorid auch deutlich von den älteren Tonträgern abgegrenzt. Die Signale werden in einer Rille gespeichert. Die Rille verläuft vom Rand der Platte in Spiralen-Form nach innen. Die Seiten der Rille bilden die Schall-Schwingung des gespeicherten Signals ab. Die Abtastspitze des Tonabnehmers wird durch die Rille geführt und bewegt sich hin und her. Die Rückverwandlung in hörbare Schall-Signale kann rein mechanisch über eine Membran und einen Schalltrichter erfolgen. Oder wie bei heute üblichen Plattenspielern auf elektromechanischem Weg mit anschließender elektronischer Verstärkung. 1860 gelang es ihm, ein französisches Kinderlied mit Hilfe eines großen Trichters einzufangen. Eine Membran übertrug die Schwingungen auf eine Schweineborste. So wurde das Lied auf eine rußgeschwärzte Walze gekratzt. Die Töne wurden zunächst in eine Zinnfolie geritzt. Später wurden sie auf einer Phonographenwalze mit wendelförmiger Tonspur in Höhenschrift gespeichert. Das Prinzip der Amplitudenauslenkung wurde auch hier unmittelbar akustisch genutzt. Dies geschah mit einer Membran oder einem Trichter. Bereits 1880 machte der US-amerikanische Physiker Charles Sumner Tainter (Columbia Graphophone Company) die Entdeckung, dass viele technische Nachteile der Edisonischen Walzen beseitigt werden könnten. Man könnte die Nachteile beseitigen, wenn man die Tonspur spiralförmig in die Oberfläche einer flachen, runden Scheibe eingraviert. Er sah auch in der schwierigen und teuren Herstellung der Walzen einen wichtigen Schwachpunkt des Phonographen. Ein Phonograph ist eine Maschine zum Abspielen von Musik von Walzen. Er verwendete seine Zeit und Mühe vor allem auf die Lösung dieses Problems. Er konstruierte ein Gerät, das die Schallwellen horizontal auslenkte - und nicht mehr, wie bei Edisons Höhenschrift-Phonographen, vertikal. Die horizontal ausgelenkten Schallwellen verursachten eine mechanische Schwingung. Mit dieser Schwingung ritzte eine  Stahlnadel schneckenförmig eine Rille auf eine Glasplatte, die zuvor dick mit Ruß beschichtet worden war. Nachdem der Ruß chemisch gehärtet wurde konnte er eine Druckvorlage für die Platte herstellen. Mit dieser Vorlage konnte man beliebig viele Platten drucken. Damit erfand er die Schallplatte. In den folgenden Monaten entwickelte Berliner gemeinsam mit dem Techniker Werner Suess sein Verfahren weiter. Das mit Ruß beschichtete Glas wurde ersetzt durch eine mit Wachs überzogene Platte aus Zink oder Kupfer. Nach dem gravieren der Schallrille in die Wachsschicht wurde die Platte in Säure gelegt. Die Säure griff die Teile der Platte die mit Wachs bedeckt waren nicht an, aber ätzte die freigelegten Rillen in das Metall ein. So entstand nach der Entfernung des Wachses eine haltbare Platte (Urplatte). Diese konnte zur Herstellung der weiteren Pressungen verwendet werden. Weil in der Zeit griechische Wörter sehr beliebt waren, nannte er es Grammophon (übersetzt: ""geschriebener Laut""). Am Anfang verwendete er zum Pressen das Material Zelluloid. Er bekam es von dem Erfinder, John W. Hyatt. Aber das Material erwies sich bald als ungeeignet. Im Juli 1889 kam Berliner durch Versuche mit unterschiedlichem Material zu dem Schluss, dass vulkanisiertes Hartgummi als Material zum Pressen am besten geeignet war. Er fand seine Erfindung gut genug um mit der Serien-Produktion zu beginnen."
5,5,5,5,5,50,6,Spielwürfel,"Ein Spielwürfel, umgangssprachlich einfach (wie auch ursprünglich) Würfel (von althochdeutsch wurfil: verwandt mit Wurf und werfen[1]), ist ein Gegenstand, der nach einem Wurf auf einer waagerechten Ebene eine von mehreren unterscheidbaren stabilen Ruhelagen einnimmt und in vielen Spielen zum Erzeugen eines zufälligen Symbols (oft einer Zufallszahl) dient. Die mit Abstand meistverbreiteten Spielwürfel sind jene mit den Ziffern 1 bis 6 oder entsprechend vielen Punkten, den Augen, beschriftete Kuben oder Hexaeder. Regelmäßige Benutzer unterschiedlicher Würfeltypen bezeichnen diese häufig mit der Abkürzung W, oder auch d für englisch dice (Einzahl auch die),[2] gefolgt von der Angabe der Seitenanzahl, also W6 oder D6 für sechsseitige, W10, W20, W30 für zehn-, zwanzig- und dreißigseitige Spielwürfel. In Würfelspielen sind Würfel das zentrale Spielelement, es zählen nur der Vergleich der Würfelergebnisse selbst oder direkt mit ihnen zusammenhängendes Taktieren. Darüber hinaus sind Würfel in einer Vielzahl von Brettspielen bedeutend, um etwa die Bewegungsgeschwindigkeit von Spielfiguren oder den Ausgang von Zufallsereignissen zu bestimmen. Verwendung finden Würfel in Rollenspielen, bei denen sich in den letzten Jahrzehnten die Verwendung einer Vielzahl weiterer Würfel mit anderen Seitenzahlen durchgesetzt hat, um die Zufallsentscheidungen flexibler und vielfältiger zu gestalten. Ein eher seltenes, komplett auf Würfel als Spielmaterial setzendes Spielprinzip ist das der Sammelwürfelspiele, bei denen man analog zu Sammelkartenspielen eine Vielzahl von Würfeln käuflich erwerben und taktisch einsetzen muss. Dabei können die Ergebnisse addiert werden (eine Waffe in einem Rollenspiel richtet soviel Schaden an, wie zwei Würfel zusammen anzeigen) oder als Ensemble betrachtet werden (bei vielen Brettspielen folgen besondere Aktionen, wenn mehrere Würfel die gleiche Zahl zeigen, bei einem sogenannten Pasch). Um das Werfen mehrerer Würfel zu vereinfachen, Schummeln durch Trickwürfe zu vermeiden oder das Ergebnis vor anderen Spielern zu verbergen, kommen Würfelbecher (Knobelbecher genannt) zum Einsatz. Um laute Aufprallgeräusche und ein Wegrollen der Würfel zu vermeiden, wird manchmal ein gepolstertes und berandetes Brett (Würfelbrett oder Würfelteller genannt) eingesetzt. Statt mit ihnen zu würfeln, also Zufallsergebnisse zu erzeugen, können Würfel gezielt auf bestimmte Werte gedreht und so zu deren Anzeige genutzt werden. Als Zufallsgenerator eingesetzt, wird von einem Würfel üblicherweise eine Gleichverteilung der möglichen Ergebnisse erwartet. Wenn man von diesen Abweichungen absieht, dann ist Idealität eine Eigenschaft des Bauplans des Würfels, also unter anderem seiner geometrischen Form. Der Bauplan ist genau dann ideal, wenn die Ruhepositionen des Würfels aufgrund seiner Symmetrie erst durch eine Beschriftung unterscheidbar werden. Bei einigen Formen kann man versuchen, dies durch die richtige Wahl der Größenverhältnisse auszugleichen, etwa durch Streckung der Seitenflächen beim nebenstehenden Prisma als siebenseitiger Würfel. Allerdings können die Landewahrscheinlichkeiten neben der Geometrie noch von anderen Bedingungen abhängen, zum Beispiel von der Reibung zwischen Würfel und Unterlage oder – auch unbeabsichtigt – von der Wurftechnik. Weitere Anforderungen sind, dass der Würfel gut – aber nicht zu lange – rollt und dass die Ruhelagen eine gewisse Stabilität aufweisen. Beim Casinospiel Craps sowie von einigen Rollenspielern ist dies jedoch verpönt, da ungleichmäßige Abrundungen bestimmte Landeflächen bevorzugen könnten. Gelegentlich wird die Wahrscheinlichkeitsverteilung bewusst zugunsten bestimmter Ergebnisse manipuliert, möglichst ohne den Würfel optisch zu verändern, um sich im Spiel einen Vorteil zu verschaffen. Zu stark gezinkte Würfel verraten sich durch eine torkelnde Rollbewegung, was beim Einsatz eines Würfelbechers aber nicht auffällt. Eine weitere Möglichkeit ist es, im Inneren des Würfels einen Dauermagneten zu platzieren, um den Würfelwurf bei Bedarf durch einen zweiten Magneten, den man z.B. unter die Tischplatte hält, zu beeinflussen.","Ein Spielwürfel ist ein Gegenstand, der nach einem Wurf auf einer geraden Fläche in einer von mehreren Positionen liegen bleibt. Spielwürfel (oder auch Würfel) werden in vielen Spielen benutzt, um ein zufälliges Symbol oder eine Zahl zu erhalten. Die meisten Spielwürfel haben Ziffern (1 bis 6) oder entsprechend viele Punkte, auch Augen genannt. Die Ziffern oder Punkte befinden sich auf einem normalen Würfel (Kubus) oder einem sechsflächigen Würfel (Hexaeder). Unterschiedliche Würfeltypen werden häufig mit der Abkürzung W bezeichnet. (englisch D für dice). Es folgt die Angabe der Seitenzahl der Spielwürfel. Beispielsweise W6 oder D6 (englisch) für sechsseitige Würfel. W 10 für zehnseitige Würfel. W20 für zwanzigseitige Würfel und W30 für dreissigseitige Würfel. Würfel sind das zentrale Spielelement von Würfelspielen.  Als Ergebnis zählt die gewürfelte Augenzahl oder vorher festgelegte Würfelmuster. Außerdem sind Würfel wichtig für viele Brettspiele. Zum Beispiel um die Bewegung von Spielfiguren oder das Ergebnis von zufälligen Entscheidungen zu bestimmen. Auch in Rollenspielen wird gewürfelt. In den letzten Jahren wurden dafür neue Würfel entwickelt. Sie haben mehr oder weniger Seiten als die klassischen Würfel. Dadurch werden die Spiele interessanter. Sammelwürfelspiele sind Spiele, die nur Würfel benutzen. Bei diesen Spielen muss man wie bei Sammelkartenspielen Würfel kaufen und taktisch einsetzen. Dabei können Ergebnisse addiert oder zusammengehörendend betrachtet werden. Eine Waffe richtet dabei in einem Rollenspiel soviel Schaden an, wie zwei Würfel zusammen anzeigen. Wenn mehrere Würfel die gleiche Zahl anzeigen (sogenannter Pasch) folgen bei vielen Brettspielen besondere Aktionen.  Damit man einfacher mehrere Würfel werfen kann, werden Würfelbecher (Knobelbecher) benutzt. Außerdem vermeidet man Schummeln und kann das Ergebnis vor anderen Spielern verbergen. Damit die Würfel nicht laut aufprallen und wegrollen wird manchmal ein gepolstertes Brett mit Rand eingesetzt. Dieses Brett nennt man Würfelbrett oder Würfelteller. Man muss mit Würfeln nicht würfeln. Man kann sie auch einfach auf eine bestimmte Seite drehen. Dann wird oben die gewünschte Zahl angezeigt. Man erwartet von einem Würfel, dass alle Ergebnisse gleich wahrscheinlich sind.  Die ideale Funktionsweise eines Würfels wird durch seine geometrische Form bestimmt.  Ein Würfel ist dann gut, wenn er von allen Seiten gleich aussieht. Nur die Beschriftung soll sich unterscheiden. Bei manchen Formen kann man versuchen die Wahrscheinlichkeit, dass eine Form auf einer Fläche landet auszugleichen. Zum Beispiel indem man eine Seitenfläche verlängert. Die Landewahrscheinlichkeiten des Würfels hängen von verschiedenen Bedingungen ab. Eine ist die Form des Würfels. Daneben sind zum Beispiel auch die Reibung zwischen Würfel und Unterlage sowie die Wurftechnik wichtig. Der Würfel muss gut rollen, nicht zu lange und dann muss er ruhig liegen. Bei dem Casionspiel Craps und bei einigen Spielern ist das aber unerwünscht. Bei ungleichen Abrundungen landen die Würfel nämlich öfter auf bestimmten Flächen. Manchmal wird die Verteilung der Wahrscheinlichkeit manipuliert, um bestimmte Ergebnisse zu erreichen. Dabei wird der Würfel möglichst optisch nicht verändert, um im Spiel einen Vorteil zu haben.  Gezinkte Würfel rollen unregelmäßiger. Das fällt aber nicht auf, wenn man einen Würfelbecher benutzt. Im Innern eines Würfels kann auch ein Dauermagnet platziert werden. Ein zweiter Magnet wird dann unter die Tischplatte gehalten.  Beim Werfen des Würfels wird der Würfelwurf dadurch beeinflusst."
6,6,6,6,6,71,7,Rasiermesser,"Seit einigen Jahren finden Rasiermesser jedoch auch zunehmend im Privatbereich wieder eine wachsende Verwendung. Die Klinge muss vor jeder Rasur auf einem Streichriemen abgeledert und in regelmäßigen Abständen nachgeschliffen werden, um die Schärfe der Schneide zu erhalten. Die Existenz von Barbieren ist durch Grabszenen belegt, so etwa im Grab des Userhet (KV45), eines hohen Beamten der 18. Dynastie (1550–1292 v. Chr.). Die Funktion dieser Messer ist laut Frank Gnegel, Autor einer Kulturgeschichte der Selbstrasur, „durch erhaltene Haarreste an den Schneiden eindeutig belegt“. In Pompeji gefundene Exemplare von frühen Klapp-Rasiermessern mit 12 Zentimeter langen trapezförmigen Klingen und Griffen aus Elfenbein gehörten als Luxusobjekte zum Hausstand höherer Schichten. Seit der Spätantike war die Bartlosigkeit ein Kennzeichen des abendländischen Klerus. Bei den Mönchsorden regelten genaue Vorschriften die Benutzung und Verwahrung der verwendeten Rasiermesser. Sie wurden in einem geschlossenen Kasten aufbewahrt und von einem eigens hierfür bestimmten Bruder vor der Verwendung geschärft. Allerdings wurde das Rasieren nicht durchgängig einheitlich gehandhabt. Mittelalterliche Bildquellen zeigen sowohl glattrasierte Kleriker als auch solche mit Vollbärten. Erleichtert wurde der Vorgang allein in Badestuben, in denen Wasser oder Dämpfe das Barthaar vor der Verwendung des Rasiermessers erweichten.","Seit einigen Jahren werden auch zuhause öfter Rasiermesser benutzt. Die Klinge muss vor jeder Rasur auf einem Lederriemen abgestrichen werden. In  regelmäßigen Abständen muss die Klinge nachgeschliffen werden, damit sie scharf bleibt.  Die Existenz von Barbieren (Friseuren) ist durch Grabszenen belegt. Man findet solche z.B. im Grab des Userhet, dies war ein hoher Beamter der 18.Dynastie (1550-1292 v.Chr.) Frank Gnegel ist Autor einer Kulturgeschichte der Selbstrasur. Ihm nach ist die Funktion dieser Messer „durch erhaltene Haarreste an den Schneiden eindeutig belegt“. In Pompeji wurden frühe Klapp-Rasiermesser gefunden. Diese hatten 12 Zentimeter lange Klingen in der Form von einem Trapez und Griffe aus Elfenbein. Sie gehörten meistens reichen Leuten und waren Luxus-Objekte. Seit der Spätantike war es ein Zeichen für die Geistlichkeiten, keinen Bart zu tragen. Bei den Mönchsorden gab es genaue Vorschriften. So wurde genau geregelt, wie Rasiermesser benutzt und verwahrt werden sollten. Sie wurden in einem geschlossenen Kasten aufbewahrt. Ein hierfür bestimmter Mönch schärfte sie vor der Verwendung.  Allerdings wurde nicht immer auf gleiche Art rasiert. Auf mittelalterlichen Bildern sieht man Geistliche mit und ohne Vollbart.  In Badstuben wurde das Barthaar mit Wasser oder Dämpfen vor dem Rasieren erweicht. Das erleichterte die Rasur mit dem Rasiermesser."
7,7,7,7,7,82,8,Vereinbarkeit von Familie und Beruf,"Unter der Vereinbarkeit von Familie und Beruf versteht man seit dem 20. Jahrhundert die Möglichkeit Erwachsener im arbeitsfähigen Alter, sich zugleich Beruf und Karriere einerseits und dem Leben in der Familie und der Betreuung von Kindern und pflegebedürftigen Personen andererseits zu widmen, unter Berücksichtigung der Schwierigkeiten, die dabei auftreten können. Eine Balance zwischen verschiedenen Lebensbereichen zu ermöglichen, gilt als eine wichtige gesellschaftspolitische Herausforderung, als ein betrieblich relevantes Thema bezüglich Wirtschaftlichkeit und Organisationskultur sowie als ein sozial, kulturell und pädagogisch bedeutsames Thema bezüglich der Gestaltung von Familienkultur. Wurde die Vereinbarkeit von Familie und Beruf ursprünglich mehr als die Frage angesehen, ob sich Mutterschaft und Berufstätigkeit überhaupt vereinbaren lassen,[1][2] entwickelte sich der gesellschaftliche Diskurs in den Industrienationen im Zuge der Emanzipation in die Richtung, wie sich für Mütter und Väter eine Berufstätigkeit mit der Erziehung der Kinder zeitlich vereinbaren lässt. Diesem Diskurs liegt die Annahme zugrunde, dass die Eltern jeweils arbeiten wollen oder müssen, dass also die elterliche Berufstätigkeit subjektiv als wertvoll betrachtet wird, etwa weil sie Zufriedenheit gewährt, Sinn stiftet, die soziale Einbindung fördert, die wirtschaftliche Existenz bzw. den Lebensstandard sichert oder weil mehrere dieser Gründe zutreffen. Angesichts der Veränderung der Altersstruktur und des Anstiegs der Lebenserwartung in vielen Ländern rückt inzwischen auch die Betreuung und Pflege älterer oder pflegebedürftiger Angehöriger stärker in den Mittelpunkt des Interesses, auch der Politik. Wortprägungen wie „weibliche Doppelverdiener“[5] wie auch der damals negativ konnotierte Begriff „Schlüsselkind“ wiesen zu dieser Zeit in Westdeutschland auf ungern gesehene Abweichungen vom Frauen- und Familienleitbild. Vielfach wurde vermutet, der technische Fortschritt des 20. Jahrhunderts werde mehrheitlich zur Verringerung der Arbeitszeit und zu einem Anwachsen der Freizeit führen. Es wird gesagt, die gegenwärtige Ausrichtung der Gesellschaft und ökonomische Zwänge hätten vielmehr zu einem Anwachsen des Konsums, zu längeren Arbeitszeiten und zu einer Abwertung des Lebensbereichs Familie geführt. Studien belegen, dass die Frage, ob Kinder aus der Situation einen Nachteil oder auch einen Vorteil beziehen, nicht mit „Ja“ oder „Nein“ beantwortet werden kann: Die Wirkung der Berufstätigkeit auf das Kind hängt von Kontextfaktoren ab, insbesondere vom Berufskontext, von der Art der Verwendung von Zeit und Geld, von der Qualität der nichtelterlichen Kinderbetreuung und von der Zufriedenheit der Frau mit ihrer Rolle. Teilweise vertreten verschiedene gesellschaftliche Gruppen jeweils den Standpunkt der Wahlfreiheit, allerdings mit unterschiedlicher Gewichtung: Die eine Seite hebt die Möglichkeit zur Erwerbsarbeit auch mit Kindern hervor, die andere betont die Freiheit, auch die traditionelle Familienform zu wählen. In Deutschland werden Infrastrukturmaßnahmen in Kombination mit Änderungen der familienbezogenen Transferleistungen und der Besteuerung insbesondere als wesentlich für eine Verringerung der Kinder- und Familienarmut genannt. Diese Erwartung wird im Zusammenhang mit der hohen Scheidungsrate, den sich ändernden Regelungen zum Unterhalt und der Diskussion um eventuelle Änderungen der Witwen-/Witwerrente in verstärktem Maß auch von der Gesellschaft an sie herangetragen. Die Pluralisierung der Familienformen mit zunehmender Zahl von Patchwork- und Einelternfamilien erfordert gesellschaftliche Anpassungen, um eine finanzielle Überforderung der Unterhalt zahlenden Eltern beziehungsweise der Sozialsysteme zu vermeiden und zugleich allen Personen einen angemessenen Lebensunterhalt zu sichern. Dies bezieht sich auf die spätere Altersrente, aber auch auf Fälle von Arbeitslosigkeit, Arbeitsunfähigkeit oder Trennung, denn bei Erwerbstätigkeit beider Partner besteht eine geringere Abhängigkeit von staatlicher Unterstützung oder Unterhaltszahlungen. In vielen Familien ist es zudem ökonomisch kaum möglich, dass sich ein Elternteil ganz der Haus- und Familienarbeit widmet – für eine zunehmende Zahl von Haushalten reicht Anfang des 21. Jahrhunderts ein Erwerbseinkommen allein nicht mehr zum Unterhalt einer Familie aus. Als Gründe dafür, dass Väter ihre Arbeitszeit relativ selten für die Familienarbeit reduzieren, werden u. a. finanzielle Nachteile aufgrund von Gehaltsunterschieden zwischen Männern und Frauen, fehlende Teilzeitstellen für höhere Positionen sowie eine Profitorientierung der Konzerne, die auf familiäre Bedürfnisse der Angestellten keine Rücksicht nehme, genannt. Eine Retraditionalisierung der Rollen findet Studien zufolge oft nach der Geburt des ersten Kindes statt: selbst bei vorher weitgehend egalitärem Rollenverständnis beider Partner werden nach der Geburt vor allem die Auffassungen der Männer wieder traditioneller, während die der Frauen egalitär bleiben; dies führe oft zu Spannungen in der Partnerschaft.","Unter der Vereinbarkeit von familie und Beruf versteht man folgendes: Erwachsene im arbeitsfähigen Alter können sich Beruf und Karriere widmen. Gleichzeitig können sie in der Familie leben und Kinder und pflegebedürftige Personen betreuen.  Eine Balance zwischen verschiedenen Lebensbereichen zu ermöglichen gilt als eine wichtige gesellschaftspolitische Herausforderung. Diese Balance ist wichtig für Wirtschaftlichkeit und Organisationskultur. Aber auch für die Gestaltung der Familienkultur ist sie ein sozial, kulturell und pädagogisch bedeutsames Thema.  Früher war die Vereinbarkeit von Familie und Beruf eher als Frage angesehen, ob Mütter sich um ihre Kinder kümmern können und einen Beruf haben können. Später wurden die Frauen immer mehr den Männern gleich gestellt (Emanzipation). Der Begriff änderte sich also dazu, wie Eltern Beruf und die Erziehung der Kinder zeitlich kombinieren können. Hier wird angenommen, dass die Eltern arbeiten wollen. Dadurch werden sie zufriedener und fühlen sich sozial eingebunden. Auch der Lebensstandard ist gesichert. In vielen Ländert verändert sich die Altersstruktur, die Lebenserwartung steigt. Deshalb sind Betreuung und Pflege älterer oder pflegebedürftiger Angehöriger in den Mittelpunkt des Interesses gerückt, auch der Politik. Abweichungen vom Frauen- und Familienbild wurden damals in der Bundesrepublik mit negativ klingenden Begriffen wie ""weibliche Doppelverdiener"" oder ""Schlüsselkind"" kritisiert. Oft wurde vermutet, dass der technische Fortschritt vom 20. Jahrhundert zu kürzeren Arbeitszeiten und mehr Freizeit führen. Es wird gesagt, dass die moderne Gesellschaft und ökonomischen Zwänge zu mehr Verbrauch (Konsum), zu längeren Arbeitszeiten und zu eine Abwertung des Familienlebens geführt hat. Studien zeigen, dass man nicht sagen kann, ob Kinder aus der Situation einen Nachteil oder Vorteil bekommen. Ob die Eltern arbeiten oder nicht wirkt auf das Kind immer unterschiedlich. Es hängt auch sehr von den Umständen ab. Die Umstände sind zum Beispiel der Beruf, die Verwendung von Zeit und Geld, die Qualität der Kinderbetreuung und davon, wie zufrieden die Frau mit ihrer Rolle ist. Verschiedene gesellschaftliche Gruppen sind für die Wahlfreiheit. Allerdings möchte die eine Gruppe, dass es auch möglich ist zu arbeiten, wenn man Kinder hat. Und die andere Gruppe findet es wichtig, dass man auch traditionelle Familienformen wählen kann.  Um Kinder- und Familienarmut zu verringern, wurden in Deutschland viele Strukturen verändert. Es wurden Steuern und Förderungs-Gelder verändert. Diese Erwartung wird noch durch die Gesellschaft verstärkt, da immer mehr Ehen geschieden werden und die Regelungen zum Unterhalt geändert wurden. Außerdem erhöht sich der Erwartungsdruck durch die Diskussion um die Änderungen der Witwen-/Witwerrente. Die Vielfalt der Familienformen mit zunehmender Zahl von Patchwork- und Einelternfamilien erfordert gesellschaftliche Anpassungen. Diese sollen die finanzielle Überforderung der Unterhalt zahlenden Eltern sowie der Sozialsysteme vermeiden. Zugleich soll allen Personen ein angemessener Lebensunterhalt gesichert werden. Dies bezieht sich auf die spätere Altersrente, aber auch auf Fälle von Arbeitslosigkeit, Arbeitsunfähigkeit oder Trennung. Bei Erwerbstätigkeit beider Partner besteht eine geringere Abhängigkeit von staatlicher Unterstützung oder Unterhaltszahlungen. Oft können es sich Familien finanziell kaum leisten, dass ein Elterteil nicht arbeiten geht. Seit dem 21. Jahrhundert reicht das Gehalt einer Person für eine Familie häufig nicht aus. Väter reduzieren ihre Arbeitszeit relativ selten für die Familienarbeit. Das kann verschiedene Gründe haben.  - Sie fürchten finanzielle Nachteile aufgrund von Gehaltsunterschieden zwischen Männern und Frauen - es gibt keine Teilzeitstellen für höhere Positionen - Konzerne nehmen auf familiäre Bedürfnisse der Angestellten keine Rücksicht, da sie profitorientiert organisiert sind Nach der Geburt des ersten Kindes findet meisten eine Rückkehr zur Traditionalisierung der Rollen statt. Auch wenn das Rollenverständnis beider Partner vorher auf Gleichheit gerichtet war, werden nach der Geburt die Auffassungen der Männer wieder traditioneller. Die der Frau hingehen bleiben auf Gleichheit fokussierte. So kommt es oft zu Spannungen in der Partnerschaft. "
8,8,8,8,8,99,9,Folgen der globalen Erwärmung,"Globale Erwärmung ist der beobachtete und prognostizierte Trend zu einer im Vergleich zu den vorindustriellen Werten höheren globalen Durchschnittstemperatur mit Folgen wie steigenden Meeresspiegeln, Gletscherschmelze, Verschiebung von Klimazonen, Vegetationszonen und Lebensräumen, verändertes Auftreten von Niederschlägen, stärkere oder häufigere Wetterextreme wie Überschwemmungen, Stürme und Dürren, Ausbreitung von Parasiten und tropischen Krankheiten sowie mehr Umweltflüchtlingen. Während über die Ursachen der globalen Erwärmung weitgehend Einigkeit besteht[1] (hauptsächlich menschliche Emissionen von Treibhausgasen), werden ihre Folgen intensiv erörtert. Nach einer Studie des Stockholm Resilience Centre von 2009 ist der ermittelte Grenzwert für den Kohlendioxidgehalt der Atmosphäre bereits um 11 % überschritten, so dass der anthropogene Klimawandel nach dem Artensterben das zweitgrößte globale ökologische Problem darstellt; er ist dabei auch ein wesentliches Merkmal des Anthropozäns sowie eine der Folgen der zunehmenden Hemerobie. Über die möglichen Folgen der Erwärmungen informieren auch die Unterartikel Folgen der globalen Erwärmung in Deutschland, Folgen der globalen Erwärmung in Europa, Folgen der globalen Erwärmung in der Arktis, Folgen der globalen Erwärmung in der Antarktis sowie Folgen der globalen Erwärmung für den Weinbau. In welchem Ausmaß die Durchschnittstemperatur im Laufe des 21. Jahrhunderts ansteigt, hängt insbesondere von der Menge an Treibhausgasen ab, die ausgestoßen werden. Dazu gehören steigende Meeresspiegel, Gletscherschmelze oder statistisch signifikante Abweichungen vom gewöhnlichen Wettergeschehen (siehe unten). Die Klimamodelle beschreiben derzeit auf globaler Ebene die Folgen recht gut, können diese jedoch auf regionaler Ebene nur recht unsicher abschätzen. Falls er in sehr kurzer Zeit erfolgen sollte, werden sowohl die ökonomischen Anpassungskosten als auch die Einflüsse auf die Natur voraussichtlich drastisch spürbar sein. Dem IPCC zufolge weisen von 29 436 Serien mit Beobachtungsdaten aus 75 Studien, die signifikante Veränderungen in physikalischen oder biologischen Systemen aufzeigen, 89 % mit den Erwartungen über eine erwärmte Welt übereinstimmende Veränderungen auf. Mit über 28.000 Datensätzen zu biologischen Veränderungen ist Europa hierbei deutlich überrepräsentiert, doch dass hiervon 90 % eine mit der Erwärmung übereinstimmende Veränderung anzeigen macht das Ergebnis auch sehr robust. Infolge der Eisschmelze in der Arktis und dem damit einhergehenden Verlust an beschwerender Masse steigt beispielsweise die Landmasse (-> „Landfläche“) Skandinaviens in Finnland und Schweden schneller als der regionale Meeresspiegel. Den Hafen des schwedischen Luleå können viele Schiffe nicht mehr anlaufen, hier sinkt der Meeresspiegel jährlich ebenfalls um nahezu einen Zentimeter, prognostiziert für noch mindestens 600 weitere Jahre. Werden keine Maßnahmen zur Bekämpfung des Klimawandels getroffen, sind weltweit 16 % aller Arten vom Aussterben bedroht, wie eine 2015 in Science erschienene Übersichtsarbeit ergab. Laut dem vom Arktischen Rat in Auftrag gegebenen Arctic Climate Impact Assessment wird in zahlreichen polaren Gebieten die Artenvielfalt zunehmen, weil im Zuge der Erwärmung neue Arten in die Arktis einwandern werden und die Gesamtzahl der Arten und deren Produktivität zunehmen wird. Würden die Meere kein Kohlendioxid lösen, läge die atmosphärische Konzentration von Kohlenstoffdioxid einer Untersuchung aus dem Jahre 2004 zufolge um 55 ppm höher, zum damaligen Zeitpunkt also statt bei 380 ppm bei wenigstens 435 ppm. Verschiedene Effekte sorgen jedoch dafür, dass mit steigenden Temperaturen und wachsendem atmosphärischem CO2-Anteil die Aufnahmefähigkeit der Meere für Kohlenstoff abnimmt. Wie weit die Aufnahmefähigkeit sinkt, lässt sich schwer beziffern. Der mögliche Kollaps von Teilen des antarktischen Eisschildes[13][14] ist in diesen Berechnungen noch eingeschlossen und würde zu massiven zusätzlichen Erhöhungen führen. Für die Meeresspiegelerhöhung werden im Wesentlichen zwei Faktoren verantwortlich gemacht: Zum einen dehnt sich das Meerwasser bei höheren Temperaturen stärker aus, zum anderen kommt es bei höheren Temperaturen zum verstärkten Abschmelzen von Gletschern (siehe unten).","Globale Erwärmung ist der beobachtete und vorhergesagte Trend zu einer höhreren weltweiten Durschnittstemperatur als vor der Industrialisierung. Folgen sind: Steigende Meeresspiegel, Gletscherschmelze, Verschiebung von Klimazonen, Vegetationszonen und Lebensräumen, verändertes Auftreten von Niederschlägen, stärkere oder häufigere Wetterextreme wie Überschwemmungen, Stürme und Dürren, Ausbreitung von Parasiten und tropischen Krankheiten sowie mehr Umweltflüchtlingen. Über die Ursachen der globalen Erwärmung ist man sich weitgehend einig. Die Ursache sind hauptsächlich durch Menschen entstandene Treibhausgase. Die Folgen der globalen Erwärmung werden aber viel diskutiert. Nach einer Studie vom Stockholm Resilience Centre von 2009 ist der Grenzwert für den Anteil von Kohlendioxid in der Atmosphäre bereits um 11% überschritten. Dadurch ist der durch die Menschen verursachte Klimawandel nach dem Artensterben das zweit größte ökologische Problem. Weitere Unterartikel informieren über die Folgen der globalen Entwicklung in Deutschland, in Europa, der Arktis und für den Weinbau. Wie stark die Temperatur im Durchschnitt im 21. Jahrhundert ansteigt, hängt vor allem von der Menge der ausgestoßenen Treibhausgase ab. Dazu gehört der steigende Meeres-Spiegel. Eine weitere Folge ist das Abschmelzen der Gletscher. Es kommt zudem zu deutlichen Abweichungen vom üblichen Wetter. Die Klima-Modelle beschreiben derzeit auf globaler Ebene die Folgen recht gut. Sie können die Folgen aber für einzelne Regionen nur sehr unsicher abschätzen. Falls der Klimawandel schnell erfolgen sollte, werden hohe Kosten enstehen und die Natur beeinflusst werden. Laut dem IPCC zeigen 75 Studien deutliche Veränderungen in physikalischen und biologischen Systemen. 89% davon weisen eine globale Erwärmung nach. Für Europa gibt es 28.000 Datensätzen zu biologischen Veränderungen. Das ist deutlich mehr als für den Rest der Welt. 90% der Daten zeigen Veränderungen, die mit einer Erwärmung übereinstimmen. Das macht das Ergebnis sehr robust. In der Arktis schmilzt das Eis. Durch das fehlende Gewicht steigt die Landfläche schnell in die Höhe. Dieses passiert in Skandinavien schneller als der Anstieg des Meeresspiegels, also die Höhe des Wassers im Meer. Betroffen sind zum Beispiel Finnland und Schweden. In dem Hafen des schwedischen Luleå können viele Schiffe nicht mehr anlegen. Dort sinkt der Meeresspiegel jährlich um fast einen Zentimeter. Das soll wohl auch die nächsten 600 Jahre weiter so sein. Ohne  Maßnahmen zur Bekämpfung des Klimawandels sind weltweit 16 % aller Arten vom Aussterben bedroht. Dies ergab eine 2015 in Science erschienene Übersichtsarbeit.  Laut dem Arctic Climate Impact Assessment, das vom Arktischen Rat in Auftrag gegebenen wurde, wird in zahlreichen polaren Gebieten die Artenvielfalt zunehmen. Grund hier ist, dass im Zuge der Erwärmung neue Arten in die Arktis einwandern werden und die Gesamtzahl der Arten und deren Produktivität zunehmen wird. Wenn die Meere kein Kohlendioxid aufnehmen würden, läge die Konzentration von Kohlenstoffdioxid in der Atmosphäre deutlich höher. Eine Untersuchungs aus dem Jahr 2004 zeigte, dass sie dann statt bei 380 ppm bei 435 ppm läge.  Bei steigender Temperaturen und steigendem Co2-Anteil in der Athmosphäre nimmt die Aufnahmefähigkeit der Meere für CO2 jedoch ab.  Es ist schwer zu sagen, wie viel weniger Kohlenstoff das Meer aufnehmen kann. Der mögliche Zusammenbruch von Teilen des antarktischen Eisschildes ist in diese Berechnungen eingeschlossen. Er würde zu massiven zusätzlichen Erhöhungen führen.  Für die Erhöhung vom Meeresstand gibt es zwei Gründe: Erstens dehnt sich Meerwasser bei höheren Temperaturen aus. Zweitens schmelzen bei höheren Temperaturen Teile von Gletschern."
9,9,9,9,9,118,10,Versauerung der Meere,"Die Folgen dieser Versauerung betreffen zunächst kalkskelettbildende Lebewesen, deren Fähigkeit, sich Schutzhüllen bzw. Innenskelette zu bilden, bei sinkendem pH-Wert nachlässt. Der pH-Wert ist für ideal verdünnte Lösungen definiert und daher auf das salzhaltige Meereswasser nicht direkt anwendbar. Um Durchschnittswerte für Meereswasser angeben zu können, müssen darüber hinaus Modelle angewendet werden, um ein chemisches Gleichgewicht des Ozeans zu simulieren. Die wichtigsten Ursachen für diese Differenz um 0,25 Einheiten sind die Temperatur des Wassers, der lokale Auftrieb von kohlenstoffdioxidreichem Tiefenwasser, sowie die biologische Produktivität, die dort, wo sie hoch ist, in Form von Meereslebewesen viel Kohlenstoffdioxid bindet und in tiefere Wasserschichten transportiert. Aus der isotopischen Zusammensetzung von Borhydroxiden lässt sich bestimmen, dass der pH-Wert an der Meeresoberfläche vor etwa 21 Millionen Jahren etwa 7,4 ± 0,2 betrug, bis er vor ungefähr 7,5 Millionen Jahren auf den Wert von 8,2 ± 0,2 stieg. Die Versauerung verläuft nach dem Fünften Sachstandsbericht des IPCC schneller als alle ähnlichen Versauerungen der vergangenen 65 Mio. Jahre, eventuell der vergangenen 300 Mio. Jahre. Einer 2005 erschienenen Studie der Stanford University zufolge, die einen vorindustriellen pH-Wert des oberflächennahen Meerwassers von durchschnittlich 8,25 annimmt, verringerte sich der pH-Wert durch die Aufnahme von Kohlenstoffdioxid auf den damaligen Wert von durchschnittlich 8,14. In beiden Fällen wird die Versauerung auf die menschlichen Emissionen von Kohlenstoffdioxid zurückgeführt und mit 0,11 pH-Einheiten beziffert. Eine Versauerung erfolgt auch in Küsten- oder Schiffsnähe durch Säureeinträge verursacht durch Schwefeloxide und Stickoxide (siehe Saurer Regen). Bei Seamounts, an den Kontinentalhängen und in Flachmeeren (zum Beispiel in Teilen des Weddell-Meeres)[10] kann das anthropogene CO2 bereits bis zum Meeresboden gelangen.","Die Folgen dieser Versauerung betreffen zuerst Tiere mit Skeletten, die vor allem aus Kalk bestehen. Diese Tiere können bei sinkendem pH-Wert nicht mehr gut Schutzhüllen und Innenskelette bilden. Der pH-Wert ist nur für ideal verdünnte Lösungen definiert. Deshalb kann man für salzhaltiges Meereswasser keinen pH-Wert bestimmen. Es müssen Modelle angewendet werden, die ein chemisches Gleichgewicht des Ozeans simulieren. Damit können dann Durchschnittswerte für Meerwasser angegeben werden.  Es gibt drei wichtige Ursachen für diese Differenz um 0,25 EInheiten: Die Temperatur des Wassers, der lokale Auftrieb von kohlenstoffdioxidreichem Tiefenwasser und die biologische Produktivität. Meereslebewesen binden viel Konhlenstoffdioxid und transportiert dieses in tiefere Wasserschichten. Aus der Zusammensetzung von bestimmten Stoffen in Ablagerungen kann man bestimmen, dass der pH-Wert an der Meeresoberfläche vor eta 21 Millionen Jahren etwa 7,4 betrug. Vor 7,5 Millionen Jahren stieg er dann auf 8,2 an. Die Versauerung verläuft nach dem fünften Bericht des IPCC schneller als alle ähnlichen Versauerungen der letzten 65 Mio. Jahre. Vielleicht sogar der vergangenen 300 Mio. Jahre. Laut einer Studie der Stanford University von 2005 verringert sich der pH-Wert durch die Aufnahme von Kohlenstoffdioxid auf durchschnittlich 8,14. Die Studie nahm an, dass der pH-Wert des oberflächlichen Meerwassers vor der Industrialisierung 8,25 war. In beiden Fällen liegt die Versauerung am Kohlenstoffdioxid, das durch Menschen entstanden ist. Die Versauerung wurde mit 0,11 pH-Einheiten gemessen. Schwefeloxide und Stickoxide sind Verbindungen aus Schwefel oder Stickstoff und Sauerstoff aus der Luft. Diese Verbindungen bringen Säure in das Meer. Besonders stark passiert das in der Nähe von Schiffen und Küsten. Das von Menschen erzeugte Kohlendioxid kann bis zum Meeresboden gelangen. Dies tritt insbesondere an den Hängen der Tiefseeberge und den Flachmeeren auf."
10,10,10,10,10,128,11,Gletscherschwund seit 1850,"Betroffen sind davon bis auf wenige Ausnahmen alle Regionen, von den Tropen über die mittleren Breiten bis zu den polaren Eiskappen. Ebenso zu beobachten ist ein Rückgang des Eises in den polaren Gebieten, wo es in den zurückliegenden Jahren vermehrt zum Abbrechen größerer Schelfeise gekommen ist. Dieser in den 1980er- und 1990er-Jahren kurzzeitig bestehende, auf örtlich veränderte Niederschlagsmuster zurückgehende Trend hat sich allerdings etwa seit dem Jahr 2000 zumindest in den ersten beiden Regionen entweder wieder umgekehrt oder ist zumindest deutlich abgeflacht. Eine indirekte Wirkung des anthropogenen Klimawandels ist eine veränderte Verteilung von Niederschlägen, die ebenfalls die Massenbilanz von Gletschern beeinflussen kann. Die Folgen des Phänomens bergen erhebliche Risiken für einen momentan nur schwer abschätzbaren Anteil der gegenwärtigen und künftigen Weltbevölkerung. Der zunehmende Abfluss des Gletscherwassers führt zudem zum globalen Anstieg des Meeresspiegels und bedroht damit auch nicht unmittelbar im Einflussbereich von Gletschern lebende Menschen. Entscheidend für das Fortbestehen eines Gletschers ist seine Massenbilanz, die Differenz von Akkumulation (wie Schneefall, Ablagerung von Triebschnee und Lawinen, Kondensation von atmosphärischem Wasserdampf und Anfrieren von Regenwasser) und Ablation (Schmelze, Sublimation sowie Abbruch von Lawinen). Im Zehrgebiet (Ablationsgebiet) dagegen überwiegt die Ablation gegenüber dem Nachschub durch Schnee. Bei einem Klimawandel können sich sowohl Lufttemperaturen als auch der Niederschlag in Form von Schnee verändern und damit die Massenbilanz verschieben. Nach dem 2007 erschienenen Vierten Sachstandsbericht der Zwischenstaatlichen Sachverständigengruppe über Klimaänderungen (IPCC) stieg die weltweite durchschnittliche Lufttemperatur in Bodennähe zwischen 1906 und 2005 um 0,74 °C (± 0,18 °C) an. Deshalb ist für jede der betroffenen Regionen gesondert zu prüfen, welche Faktoren für den Rückgang der Gletscher ursächlich und gegebenenfalls dominierend sind. Kryokonit ist ein dunkler biogener Oberflächenstaub auf Schnee und Eis, der durch Winde in der Atmosphäre über weite Strecken transportiert wird und gewöhnlich auf Gletschern weltweit zu beobachten ist. Wegen seiner dunklen Färbung reduziert Kryokonit wesentlich die Oberflächenreflexion des Sonnenlichts und beschleunigt oder initiiert damit das Schmelzen der Gletscher. Dieses organische Material besteht zum Teil aus photosynthetisch aktiven Mikroorganismen wie Cyanobakterien oder auch Bärtierchen,[13] wie es am Rotmoosferner nachgewiesen wurde. Dadurch nimmt die Gletscherfläche im Zehrgebiet, dort ist die Ablation am höchsten, zu. Auf eine Klimaerwärmung wie die globale Erwärmung oder eine Abnahme des Schneefalls, die zu einer negativen Massenbilanz führen, reagiert der Gletscher mit einem Rückgang.","Betroffen sind bis auf wenige Ausnahmen alle Regionen. Die Tropen, die mittleren Breiten und die polaren Eiskappen. Außerdem kann man beobachten wie das Eis in polaren Gebieten zurückgeht. Dort sind in den vergangenen Jahren große Flächen von Eis abgebrochen. In den 1980er- und 1990er Jahren entstand der Trend durch örtlich veränderte Regen-Muster. Dieser Trend hat sich aber seit 2000 zumindest in den ersten Regionen umgekehrt oder hat abgenommen.  Eine indirekte Wirkung von dem durch die Menschen verursachten Klimawandels ist die veränderte Verteilung von Regen. Diese Veränderung kann verändern, wie viel Masse ein Gletscher zunimmt oder abnimmt. Die Folgen können gefährlich sein für einen momentan schwer zu schätzenden Anteil der aktuellen und zukünftigen Weltbevölkerung, Der Abfluss des Gletscherwassers nimmt zu und führt zudem zum weltweiten Anstieg des Meeresspiegels. Er bedroht damit auch Menschen, die nicht unmittelbar im Einflussbereich von Gletschern leben. Damit ein Gletscher weiter besteht, ist seine Massen-Bilanz wichtig. Die Massenbilanz ist der Unterschied von Zuwachs durch Schneefall und Gefrieren von Regenwasser und das Abnehmen durch Schmelze und Abbrüche. Im so genannten Zehrgebiet verliert der Gletscher mehr Masse als er durch Schneefall zunimmt. Dieses Gebiet nennt man auch Ablationsgebiet. Bei einem Klimawandel können sich die Temperatur der Luft und der Niederschlag verändern. Damit kann sich der Unterschied zwischen Zufluss und Masseverlust von Gletschern verschieben. Nach dem vierten Bericht in 2007 stieg die weltweite durchschnittliche Lufttemperatur in Bodennähe zwischen 1906 und 2005 um 0,74 Celsius (+-0,18 C) an. Der Bericht wurde geschrieben von der IPCC, einer Umwelt-Gruppe für Kilmaänderungen.  Die Ursachen für den Rückgang der Gletscher müssen deshalb für jede Region einzeln geprüft werden. Dann versteht man die Größe und Relevanz der Faktoren.  Kryokonit ist ein dunkler organischer Staub auf Schnee und Eis. Der Staub wird durch Winde in der Atmosphäre über weite Strecken transportiert. Man kann den Staub meistens auf Gletschern sehen. Wegen seiner dunklen Färbung vermindert Kryokonit die Oberflächenreflexion des Sonnenlichts sehr stark. Deshalb kommt es zu einer noch schnelleren Abschmelze der Gletscher. Dieses natürliche Material ist zum Teil aus Mikroorganismen, die auf Licht reagieren und daraus Energie erzeugen können. Mikroorganismen sind zum Beispiel Cyanobakterien oder Bärtierchen. Diese wurden zum Beispiel am Rotmoosferner gefunden. Dadurch werden die Gletscher im unterer Teil des Gletschers größer. In diesem Gebiet schmilzt oft am meisten Schnee und Eis ab. Gletscher nehmen ab, wenn sich das Klima erwärmt, wie bei der globalen Erwärmung. Außerdem nehmen Gletscher ab, wenn weniger Schnee fällt, was zu einem negativen Verhältnis von Zuwachs und Abschmelzen des Gletschers führt (negative Massenbilanz)."
11,11,11,11,11,144,12,Klimageschichte,"Letztere verzeichnet auch die verschiedenen Wetteranomalien in historischer Zeit, die unter anderem von heftigen vulkanischen Eruptionen hervorgerufen wurden. Zuverlässige und instrumentell ermittelte Temperatur- und Klimadaten stehen auf breiterer Basis erst seit der zweiten Hälfte des 19. Jahrhunderts zur Verfügung. Zusätzlich kommt in der Forschung ein breites Spektrum verschiedener Isotopenanalysen zum Einsatz, deren jüngste Entwicklungen eine bis vor kurzem unerreichbare Messgenauigkeit ermöglichen. Allerdings deckt die 14C-Methode nur einen relativ schmalen zeitlichen Bereich von 300 bis maximal 57.000 Jahren ab. In letzter Zeit kommt die 40Ar/39Ar-Datierung verstärkt zum Einsatz, da diese Methode auf der Grundlage des Edelgases Argon erheblich präzisere Ergebnisse als die herkömmliche Kalium-Argon-Datierung ermöglicht. So gab es noch keine Meere, Niederschläge oder sonstiges flüssiges Wasser auf der Erde, und die Zusammensetzung der reduzierenden Uratmosphäre unterschied sich stark von der heutigen Erdatmosphäre. Vor 2,6 Milliarden Jahren bildete sich im Laufe der Entwicklung der Erdatmosphäre durch die Aktivität von Cyanobakterien der erste Sauerstoff in der Uratmosphäre und erreichte vor circa 2,2 Milliarden Jahren signifikante Konzentrationen. Die Veränderung der Konzentration der Klimagase und ihrer Zusammensetzung veränderte zudem den Strahlungshaushalt der Erde und brachte den Treibhauseffekt in Gang, der die Erde seitdem erwärmt.","Die Historische Klimatologie ist die Forschung in der die unüblichen Änderungen von dem Wetter in historischen Zeiten beschrieben werden. Sie wurden unter anderem von Vulkanausbrüchen hervorgerufen. Gemessene Temperatur- und Klimadaten gibt es erst seit der zweiten Hälfte des 19. Jahrhunderts. Außerdem werden in der Forschung viele verschiedene Isotopenanalysen eingesetzt. Ihre jüngste Entwicklung ermöglichen ermöglichen eine bis vor kurzem unerreichbare Messgenauigkeit. Mit der 14C-Methode kann man allerdings nur einen relativ kleinen Zeitraum untersuchen. Dieser reicht von 300 bis 57.000 Jahren.  Immer mehr benutzt man die 40Ar/39Ar-Datierung. Sie basiert auf Argon und ist genauer als die normale Kalium-Argon-Datierung. Es gab damals noch keine Meere, Regen oder sonstiges flüssiges Wasser auf der Erde. Die Urathmosphäre war sehr anders als die heutige Erdatmosphäre. Im Laufe der Entwicklung der Erdatmosphäre bildete sich vor 2,6 Milliarden Jahren  der erste Sauerstoff in der Uratmosphäre. Dies lag an der Aktivität von Cyanobakterien. Dieser Sauerstoff erreichte vor circa 2,2 Milliarden Jahren bedeutende Konzentrationen. Die Konzentration und Zusammensetzung der Klimagase veränderten den Strahlungshaushalt der Erde. Es kam zu einem Treibhauseffekt, der die Erde seitdem erwärmt.  "
12,12,12,12,12,152,13,Geothermie,"Sie umfasst die in der Erde gespeicherte Energie, soweit sie entzogen und genutzt werden kann, und zählt zu den regenerativen Energien. Sie kann sowohl direkt genutzt werden, etwa zum Heizen und Kühlen im Wärmemarkt (Wärmepumpenheizung), als auch zur Erzeugung von elektrischem Strom oder in einer Kraft-Wärme-Kopplung. Dieser Temperaturgradient ist mit etwa 1 K/km viel zu klein, als dass Wärmeleitung einen wesentlichen Beitrag zum Wärmetransport leisten könnte. Die im Vergleich zum Erdalter sehr rasche Konvektion – die ozeanische Kruste wurde und wird selten älter als 100 Millionen Jahre – wäre ohne Wärmequellen bald zum Erliegen gekommen. Das ist nur etwa das Doppelte des Weltenergiebedarfs, was bedeutet, dass Erdwärmenutzung im großen Stil immer auf eine lokale Abkühlung des Gesteins hinausläuft. Aufgrund der Wärmekapazität des Gesteins, und der damit verbundenen Menge der gespeicherten Wärme kann aber bei ausreichend großem Volumen die Abkühlung innerhalb der Nutzungsdauer gering bleiben und die Erdwärmenutzung somit nachhaltig sein. Diese finden sich beispielsweise in Grabenbrüchen (in Deutschland der Oberrheingraben) oder in tiefen Sedimentbecken. Solche Gebiete sind zunächst Gebieten vorzuziehen, in denen ein dichtes Gestein für die Konvektion erst erschlossen werden muss. Dies sind geologische Wärmeanomalien, die oft mit aktivem Magmatismus einhergehen; dort sind mehrere hundert Grad heiße Fluide (Wasser/Dampf) in einer Tiefe von wenigen hundert Metern anzutreffen. Abhängig von den Druck- und Temperaturbedingungen können Hochenthalpie-Lagerstätten mehr dampf- oder mehr wasserdominiert sein. Hierfür wird das im Untergrund erhitzte Wasser genutzt, um eine Dampfturbine anzutreiben. Der geschlossene Kreislauf im Zirkulationssystem steht so unter Druck, dass ein Sieden des eingepressten Wassers verhindert wird und der Dampf erst an der Turbine entsteht (Flash-Verdampfung). In der Regel sind jedoch tiefe Bohrungen notwendig; für die Stromerzeugung sind Temperaturen über 80 °C erforderlich. Generell werden im Bereich der tiefen Geothermie drei Arten der Wärmeentnahme aus dem Untergrund unterschieden; welches der in Frage kommenden Verfahren zum Einsatz kommt, ist von den jeweiligen geologischen Voraussetzungen, von der benötigten Energiemenge sowie dem geforderten Temperaturniveau der Wärmenutzung abhängig. HDR-Verfahren befinden sich in den Pilotprojekten in Bad Urach (D), in Soultz-sous-Forêts im Elsass (F) und in Basel (CH) in der Erprobung.","Erdwärme ist die in der Erde gespeicherte Energie, wenn sie entzogen und genutzt werden kann. Die Erdwärme zählt zu den erneuerbaren Energien. Die Wärme kann direkt genutzt werden. Zum Beispiel zum Heizen oder Kühlen (mit Wärmepumpheizungen). Sie kann auch genutzt werden um Strom zu erzeugen. Dieser Temperaturgradient ist mit etwa 1K/km sehr klein. Daher kann er keinen wesentlichen Beitrag zum Wärmetransport leisten. Ohne Wärmequellen kommt es nicht zum Strömungstransport. Die ozeanische Kruste wurde und wird selten älter als 100 Millionen Jahre. Das ist nur etwa das Doppelte des Energiebedarfs der Welt. Das bedeutet, dass die Benutzung von Erdwärme immer dazu führt, dass an sich diesen Stellen das Gestein abkühlt. Die Erdwärmenutzung kann nachhaltig sein, weil das Gestein viel Wärme aufnehmen kann. Bei ausrechend großem Volumen kann die Abkühlung sehr lange dauern. Duckgradienten wachsen in Grabenbrüchen. Das sind Spalten oder Risse in der Erdoberfläche. Auch wachsen Duckgradienten in tiefen sandähnlichen Regionen. In Deutschland wachsen Duckgradienten zum Beispiel im Oberrheingraben.  Solche Gebiete werden eher als andere Gebiete genutzt, in denen dichtes Gestein erst gefunden werden muss. Das dichte Gestein ist notwendig, um Wärme zu leiten. Dies sind geologische Wärmeanomalien, in denen man oft aktives Magma findet. Dort gibt es wenige hundert Meter tief sehr heißen Dampf. Die ebengenannten Hochenthalpie- Lagerstätten sind abhängig von Druck- und Temperaturbedingungen. Sie können mehr dampf- oder wasserdominiert sein.  Hierfür wird das im Untergrund erhitzte Wasser genutzt, um eine Dampfturbine anzutreiben. Der geschlossene Kreislauf im System steht so unter Druck, dass das Wasser nicht direkt kocht, sondern der Dampf erst an der Turbine entsteht. Das nennt man Flash-Verdampfung. Normalerweise muss man tief bohren. Für die Stromerzeugung braucht man Temperaturen über 80 Grad Celsius. Es gibt in der tiefen Geothermie drei Arten der Wärmeentnahme aus dem Boden. Welche der drei eingesetzt wird, ist von den geologischen Voraussetzungen abhängig. Außerdem ist entscheiden, welche Energiemenge benötigt wird und wie hoch die Temperatur der Wärmenutzung sein soll. HDR-Verfahren werden in Beispielprojekten getestet. Diese Projekte befinden sich in Bad Urach (D), in Soultz-sous-Forêts im Elsass (F) und in Basel (CH)."
13,13,13,13,13,166,14,Glacier-Nationalpark (Vereinigte Staaten),"Er wurde am 11. Mai 1910 unter Schutz gestellt, wird vom National Park Service verwaltet und dient wegen seiner langen Forschungsgeschichte als Referenzgebiet für die Erforschung der Klimageschichte und der globalen Erwärmung. Beide Parks zusammen wurden 1932 als weltweit erstes grenzüberschreitendes Naturschutzgebiet unter dem Namen Waterton-Glacier International Peace Park zu einem „Internationalen Friedenspark“ ernannt und 1995 durch die UNESCO zum Weltnaturerbe erklärt. Der Glacier-Nationalpark bezieht seinen Namen von der durch Vergletscherung während des Eiszeitalters geprägten Landschaft. Der Berg ist der Wasserscheidepunkt an dessen Flanken sich die Einzugsgebiete des Pazifischen Ozeans, des Atlantischen Ozeans über den Golf von Mexiko und des Arktischen Ozeans über die Hudson Bay berühren. In den Tieflagen liegen Zungenbeckenseen, im höheren Gelände handelt es sich um Karseen. Der Westen unterliegt dem maritimen Einfluss des Pazifischen Ozeans mit gemäßigten Temperaturen und hohen Niederschlägen, während die Ostseite dem kontinentalen Klima zugehörig ist, das durch extreme jahreszeitliche Temperaturunterschiede und die für Nordamerika typischen Blizzards aus nördlichen Richtungen geprägt ist. Spannungen innerhalb der Decke führten zu einer Synklinale, einer konkav – also nach innen – gewölbten Struktur, durch die Gesteinsschichten im Osten und Westen des Parks höher liegen als im Zentrum. Aus den Ablagerungen von Sanden, Tonen und den Kalkgehäusen von Zooplankton in einem Urmeer entstanden zunächst Gesteine wie Sandstein, Schiefer und Kalkstein. Teile davon wurden über geologische Zeiträume durch Druck späterer Schichten zu Metamorphen Gesteinen wie Quarzit, Tonschiefer sowie kristallinem Kalkstein (Marmor) und Dolomit umgewandelt. In der Appekunny Formation im Osten des Parks, die auf ein Alter von 1,5–1,3 Milliarden Jahre datiert wird, wurden 1982 Abdrücke gefunden, die von den Entdeckern als Metazoa interpretiert und nach neuen Untersuchungen 2002 als Horodyskia moniliformis beschrieben wurden. Sie gehören zu den frühesten Spuren vielzelliger Tiere weltweit.","Der Park wurde am 11. Mai 1910 unter Schutz gestellt und wird vom National Park Service verwaltet. Er wurde schon lange erforscht. Deshalb wird er oft als Beispiel-Gebiet für die Erforschung der Geschichte des Klimas und der globalen Erwärmung genutzt. Beide Parks wurden 1932 zu einem gemeinsamen Naturschutzgebiet ernannt. Das Gebiet war das erste, das über mehrere Grenzen reichte. Es wurde mit dem Namen ""Waterton-Glacier International Peace Park"" zu einem internationalen Friedenspark ernannt. Und 1995 wurde es durch die UNESCO zum Weltkulturerbe erklärt. Während des Eiszeitalters prägten Gletscher die Landschaft. Auf diese Tatsache bezieht sich der Name des Glacier-Nationalparks. Der Berg markiert die Grenze zwischen den Gebieten des Pazifischen Ozeans, des Atlantischen Ozean und des Arktischen Ozeans.  In den Tälern liegen Seen, die man Zungenbeckenseen nennt. In den höheren Gegenden sind Seen, die man Karseen nennt. Durch den Einfluss des Pazifischen Ozeans unterliegt der Westen gemässigten Temperaturen und hohen Niederschlägen. Die Ostseite ist dem Landklima zugehörig. Es ist durch sehr starke jahreszeitliche Temperaturunterschiede geprägt. Aus nördlichen Richtungen kommen schwere Schneestürme. Diese sind für Nordamerika typisch. Spannungen innerhalb der Decke führten zu einer konkaven - also nach innen - gewölbten Struktur. Aufgrund dieser Struktur (auch Synklinale genannt) liegen die Gesteinsschichten im Osten und Westen des Parks höher als im Zentrum.  Aus den Sand-, Ton- und Kalkablagerungen in einem ehemaligen Meer entstanden zuerst Gesteine wie Sandstein, Schiefer und Kalkstein. Teile davon wurden über lange Zeit durch den Druck späterer Schichten zu Gesteinen umgewandelt. Diese Gesteine sind zum Beispiel Quarzit, Tonschiefer, kristalliner Kalkstein (Marmor) und Dolomit. In der Appekunny Formation im Osten des Parks, die auf ein Alter von 1,5-1,3 Milliarden Jahre datiert wird, wurden 1982 Abdrücke gefunden. Diese Abdrücke wurden von den Entdeckern als vielzellige Lebenwesen (Metazoa) interpretiert. Nach neuen Untersuchungen wurden diese Metazoa als Horodyskai moniliformis beschrieben.  Sie gehören zu den frühsten Spuren von Tieren, die aus mehreren Zellen bestehen."
14,14,14,14,14,177,15,Recycling,"Beim Recycling, Rezyklierung bzw. Müllverwertung werden Abfallprodukte wiederverwertet bzw. deren Ausgangsmaterialien werden zu Sekundärrohstoffen. Ein möglicher Nachteil von beispielsweise Kunststoff ist, dass – bei vertretbarem Aufwand – das Material nicht mehr die ursprüngliche Qualität oder dessen Verarbeitbarkeit erreicht wie bei der Primärherstellung vor dem Recyclingprozess. Diese Abwertung wird auch als Downcycling bezeichnet, während beim Upcycling aus Abfallstoffen eines Prozesses hochwertigere Produkte hergestellt werden können.  Es kommt hierbei auf die Qualität und Sortenreinheit der gesammelten Altteile und den Aufbereitungsprozess und die Nachadditivierung an. Auch der Gesamtenergieverbrauch bei der Wiederaufbereitung wird vielfach überschätzt. Diese vollständige Wiederverwertung ist Basis der Subsistenzwirtschaft. Im Mittelalter verfiel diese Organisation größtenteils – Exkremente und Abfälle wurden teilweise einfach nur auf die Straße gekippt und allenfalls von Haustieren „verwertet“. Erst mit Aufkommen der grünen Bewegung in den 1970/80er-Jahren fand ein Umdenken statt, dass Müllentsorgung einer der Hauptfaktoren der Umweltverschmutzung darstellt. Ausgehend von Altpapier-Wiederverwendung wurden zunehmend Technologien erarbeitet, die die Wiederaufbereitung aller Arten von Altstoffen wirtschaftlich machen, wodurch Abfall zu einem bedeutenden Wirtschaftsgut wurde: Geprägt wurde dafür der Ausdruck Sekundärrohstoff. Besonders in Zeiten der Kriegswirtschaft wird auf Metallgegenstände des zivilen Gebrauches zurückgegriffen zwecks Sekundär-Rohstoffgewinnung zur Waffenproduktion, wie etwa 1940 unter dem Motto Metallspende des deutschen Volkes.","Bei der Müllverwertung werden Abfallprodukte wieder verwertet. Dieser Vorgang wird auch Recycling genannt. Das Recycling von Kunststoff hat einen möglichen Nachteil. Dieser ist, dass das Material nach dem Recyclingprozess nicht die gleiche Qualität hat, wie bei der ersten Produktion. Um die gleiche Qualität zu erreichen, wäre der Aufwand zu groß. Man nennt das auch Downcycling. Beim so genannten Upcycling werden aus Abfallstoffen eines Produktes bessere Produkte hergestellt. Es kommt dabei auf die Qualität und Reinheit der gesammelten alten Teile an. Auch die Aufbereitung und weitere Zuführung von weiteren Stoffen ist wichtig. Viele überschätzen den Gesamtenergieverbrauch bei der Wiederaufbereitung. Diese vollständige Wiederverwertung ist Grundlage für eine Wirtschaft, die auf Selbstversorgung setzt (Substinenzwirtschaft). Im Mittelalter wurde diese Organisation meist nicht mehr gemacht. Ausscheidungen und Abfälle wurden manchmal einfach nur auf die Straße gekippt oder an Tiere verfüttert. Erst durch die grüne Bewegung in den 1970/80er-Jahren dachten die Menschen anders. Erst dann erkannten sie, dass die Müllentsorgung einer der größten Gründe für die Umweltverschmutzung ist. Ausgehend von Altpapier-Wiederverwendung wurden zunehmend Technologien erarbeitet, die die Wiederaufbereitung aller Arten von Altstoffen wirtschaftlich machen. Dadurch wurde Abfall zu einem bedeutenden Wirtschaftsgut. Dafür entstand der Ausdruck Sekundärrohstoff. Während des Krieges werden oft Alltagsgegenstände aus Metall eingeschmolzen und für die Waffenproduktion genutzt. Ein Beispiel ist die Aktion ""Metallspende des deutschen Volkes"" von 1940. "
15,15,15,15,15,187,16,Winston Churchill,"Zuvor hatte er bereits mehrere Regierungsämter bekleidet, unter anderem das des Innenministers, des Ersten Lords der Admiralität und des Schatzkanzlers. Erst bei Ausbruch des Zweiten Weltkriegs 1939 kehrte Churchill, der als erklärter Gegner Hitlers bekannt war, in die Regierung zurück, zunächst erneut als Erster Lord der Admiralität. Mit seiner Weigerung, in Verhandlungen mit Hitler einzutreten, und mit seinen Reden stärkte er in den kritischen Monaten des Frühjahrs und Sommers 1940 den britischen Widerstandswillen. Seinen Wahlkreis Woodford im Nordosten Londons vertrat er bis 1964, ein Jahr vor seinem Tod, im Unterhaus. Das autoritäre Erziehungssystem dort widerstrebte ihm, und er blieb mehrfach sitzen. Zwischen 1895 und 1901 nahm Churchill als aktiver Soldat und Kriegsberichterstatter an fünf verschiedenen Kolonialkriegen teil, unter anderem in Kuba auf Seiten der Spanier während des dortigen Unabhängigkeitskrieges und in verschiedenen Teilen des Empire, etwa in Malakand in der Nordwestlichen Grenzprovinz Britisch-Indiens. Dabei ritt er in der Schlacht von Omdurman eine der letzten großen Kavallerieattacken der britischen Militärgeschichte mit. Seinem Biographen Martin Gilbert zufolge war der Vertrag, den Churchill mit der Zeitung aushandelte, „wahrscheinlich der günstigste Vertrag, den überhaupt ein Kriegsberichterstatter bis dahin abgeschlossen hatte“.","Zuvor hatte er bereits mehrere Regierungsämter bekleidet. Unter anderem war er Innenminister, Erster Lord der Admiralität und Schatzkanzler. Als 1939 der zweite Weltkrieg ausbrach, wurde Winston Churchill wieder Mitglied der Regierung. Er war als Gegner von Hitler bekannt. Seine neue Position war die des Ersten Lords der Admiralität. Er verweigerte mit Hitler zu verhandeln. Damit und mit seinen Reden stärkte er den Widerstandswillen der Briten in den wichtigen Monaten im Frühling und Sommer 1940. Bis ein Jahr vor seinem Tod 1965 arbeitete er noch im Unterhaus. Er vertrat dort seinen Wahlkreis  Woodford im Nordosten von London. Die befehlerische Erziehung dort gefiel ihm nicht und er blieb mehrfach sitzen. Zwischen 1895 und 1901 nahm Churchill als aktiver Soldat und Kriegsberichterstatter an fünf verschiedenen Kolonialkriegen teil. Unter anderem kämpfte und arbeitete er in Kuba auf der Seite der Spanier während des dortigen Unabhängigkeitskrieges. Außerdem war er in verschiedenen Teilen des Empire, etwa in Malakandin der Nordwestlichen Grenzprovinz Britisch-Indiens aktiv beteiligt. Er ritt in der Schlacht von Omdurman mit. Das war einer der letzten großen Angriffe von Soldaten auf Pferden in der britischen Militärgeschichte. Churchills Vertrag mit der Zeitung war laut seines Biographen der beste Vertrag, den ein Kriegsberichterstatter je ausgehandelt hatte."
16,16,16,16,16,195,17,Friedensnobelpreis,"Die Ursache für die Vergabe durch ein norwegisches Gremium liegt vermutlich darin, dass zu Nobels Lebzeiten Schweden und Norwegen vereinigt waren und außenpolitische Fragen nur durch das schwedische Parlament entschieden wurden. Man geht allerdings davon aus, dass er der Meinung war, das norwegische Parlament, das nur für die Innenpolitik verantwortlich war, wäre Manipulationen durch die Regierung weniger stark ausgesetzt. 1977 wurde die Regel insofern noch einmal verschärft, dass keine Mitglieder aus regierungsnahen Ausschüssen zugelassen werden, gleichzeitig mit der Namensänderung von „Nobel-Komitee des norwegischen Parlamentes“ in „Norwegisches Nobel-Komitee“. Die ausgewählten Personen und Organisationen wirken häufig stark polarisierend, und es kommt bei nahezu jeder Vergabe zu Anfeindungen über die Entscheidung. Eine Rücknahme des Preises ist jedoch nicht möglich und die Entscheidung des Gremiums entsprechend nicht formal anfechtbar. Das Komitee zog eine posthume Vergabe in Betracht und prüfte sie.","Die Vergabe wird durch ein norwegisches Gremium gemacht. Das liegt daran, dass als Nobel noch lebte Schweden und Norwegen vereinigt waren. Außenpolitische Fragen wurden damals nur durch das schwedische Parlament entschieden. Nobel dachte, dass das norwegische Parlament weniger von der Regierung beeinflusst werden kann, da es nur für Innenpolitik verantwortlich ist.  1977 wurde die Regel noch einmal verschärft. Es wurden keine Mitglieder zugelassen aus Auschüssen, die mit der Regierung verbunden waren. Das geschah gleichzeitig mit der Namensänderung von „Nobel-Komitee des norwegischen Parlamentes“ in „Norwegisches Nobel-Komitee“. Die gewählten Personen und Organisationen führen oft zu großen Diskussionen. Es gibt bei fast jeder Vergabe zu Streit über die Entscheidung. Eine Rücknahme des Preises ist unmöglich. Die Entscheidung des Gremiums steht fest.  Das Komitee überlegte, ihm noch nach seinem Tod den Preis zu verleihen."
17,17,17,17,17,201,18,Britisches Weltreich,"Unter der Herrschaft des Vereinigten Königreichs vereinte es Dominions, Kronkolonien, Protektorate, Mandatsgebiete und sonstige abhängige Gebiete, die aus den englischen Überseebesitzungen, Handelsposten und Strafkolonien hervorgegangen waren. Die Abspaltung der Dreizehn Kolonien nach dem Amerikanischen Unabhängigkeitskrieg (1775–1783) bedeutete zwar den Verlust der bevölkerungsreichsten Überseegebiete, doch wandte sich Großbritannien bald Afrika, Asien und Ozeanien zu. Mehrere Siedlerkolonien, deren Bevölkerung vor allem durch den stetigen Zustrom von Auswanderern aus dem Mutterland zunahm, erhielten mit der Zeit mehr Autonomie und wurden zu Dominions erhoben. Damals kaufte die konservative Regierung Disraeli für 4 Millionen Pfund die Aktienanteile des ägyptischen Herrschers Ismail an der Sueskanal-Gesellschaft auf, um diesen strategisch wichtigen Handelsweg nach Indien zu sichern. Die Rivalität zu Russland (vgl.: The Great Game), die im Krimkrieg (1854–1856) eine erste Eskalation erfahren hatte, und die Angst vor einer russischen Expansion in Richtung Süden und Indien war ein weiterer Faktor der britischen Politik.  Wegen des wachsenden Einflusses des Deutschen Reiches und der Vereinigten Staaten büßte Großbritannien seit etwa 1900 zunehmend seine politische und wirtschaftliche Vormachtstellung ein. Wirtschaftliche und politische Spannungen mit dem Deutschen Reich gehören zu den wichtigsten Ursachen des Ersten Weltkriegs, in dem Großbritannien in hohem Maße auf die Unterstützung durch seine Kolonien angewiesen war. Zwar erreichte Großbritannien nach Kriegsende 1918 durch die Übernahme deutscher Kolonien seine größte Ausdehnung, doch leiteten finanzielle Probleme und zunehmende Autonomiebestrebungen das Ende seiner globalen Bedeutung ein. Darüber unterstehen 14 kleinere Überseegebiete weiterhin der britischen Souveränität. Premierminister David Lloyd George honorierte diesen wichtigen Beitrag, indem er 1917 mit den Premierministern der Dominions das Reichskriegskabinett (Imperial War Cabinet) bildete, um die gemeinsamen Anstrengungen zu koordinieren.","Unter der Herrschaft des Vereinigten Königreichs vereinte es abhängige Gebiete. Dies waren Überseebesitzungen, Handelsposten und Strafkolonien. Aus diesen Gebieten waren Dominions, Kronkolonien, Protektorate, Mandatsgebiete und andere Gebiete hervorgegangen.  Mit der Abspaltung der 13 Kolonien hatte Großbritannien nach dem Amerikanischen Unabhängigkeitskrieg seine bevölkerungsreichsten Überseegebiete verloren. Dafür wandte es sich nun Afrika, Asien und Ozeanien zu. Die Siedlerkolonien, deren Bevölkerung immer größer wurde, wurden mit der Zeit immer unabhängig und zu eigenständigen Staaten ernannt. Damals kaufte die konservative Regierung Disraeli für 4 Millionen Pfund Aktien-Teile an der Sueskanal-Gesellschaft des ägyptischen Herrschers Ismail auf. Sie taten das, um diesen strategisch wichtigen Handelsweg nach Indien zu sichern. Die Konkurrenz mit Russland verschärfte sich im Krimkrieg (1854-1856).  Außerdem hatten die Briten Angst vor einer Ausweitung des russischen Gebiets in den Süden und nach Indien. Seit 1900 verringerte sich die politische und wirtschaftlich führende Rolle von Großbritannien. Grund dafür war der steigende Einfluss des Deutschen Reiches und der Vereinigten Staaten.  Eine der wichtigsten Ursachen des ersten Weltkriegs war die wirtschaftliche und politische Spannung mit dem Deutschen Reich. In dem Krieg war Großbritannien sehr auf die Unterstützungen der Kolonien angewiesen. Nach Kriegsende 1918 war Großbritannien durch die Übernahme von deutschen Kolonien am größten. Aber Geld-Probleme und Forderungen nach Unabhängigkeit führten bald zum Ende der weltweiten Bedeutung. 14 kleinere Überseegebiete werden weiterhin durch Großbritannien regiert. Premierminister David Lloyd George belohnte diesen wichtigen Beitrag. Er gründete 1917 zusammen mit den Premierministern der Dominions das Reichskriegskabinett. Dort wurden die gemeinsamen Bemühungen koordiniert."
18,18,18,18,18,211,19,Albert Einstein,"Seine Forschungen zur Struktur von Materie, Raum und Zeit sowie zum Wesen der Gravitation veränderten maßgeblich das zuvor geltende newtonsche Weltbild. Sein Vater Hermann Einstein stammte aus der oberschwäbischen Kleinstadt Buchau, in der es seit dem Mittelalter innerhalb des Territoriums des freiweltlichen Damenstifts Buchau eine bedeutende jüdische Gemeinde gab (siehe auch: Familie Einstein in Bad Buchau). Der erste namentlich nachgewiesene Vorfahre Albert Einsteins, ein aus dem Bodenseeraum stammender Pferde- und Tuchhändler namens Baruch Moses Ainstein, wurde im 17. Jahrhundert in die Gemeinde aufgenommen. In der Schule war er ein aufgeweckter, bisweilen gar aufrührerischer Schüler.","Seine Forschung zur Struktur von Materie, Raum, Zeit und Gravitation veränderten das Weltbild. Das Weltbild war zuvor von einem anderen Forscher, der Newton hieß, geprägt. Sein Vater Hermann Einstein stammte aus der kleinen Stadt Buchau, die in Oberschwaben liegt. In der Stadt gab es seit dem Mittelalter eine wichtige jüdische Gemeinde.  Der erste Vorfahre von Albert Einstein wurde im 17. Jahrhundert in die Gemeinde aufgenommen. Er hieß Baruch Moses Ainstein und war ein Pferde- und Tuchhändler. Er stammte aus dem Bodenseeraum. In der Schule war er ein aufgeweckter Schüler. Manchmal war er etwas frech."
19,19,19,19,19,215,20,Novemberrevolution,"Er sah vor, die deutsche Hochseeflotte trotz der bereits feststehenden Kriegsniederlage Deutschlands in eine letzte Schlacht gegen die britische Royal Navy zu entsenden. Über die Parlamentarisierung hinausgehende, von rätedemokratischen Ideen geleitete Ziele des linken Flügels der Revolutionäre scheiterten am Widerstand der SPD-Führung. Der Flottenbefehl vom 24. Oktober 1918 und die Vorbereitungen zum Auslaufen lösten zunächst eine Meuterei unter den betroffenen Matrosen und dann eine allgemeine Revolution aus, die in wenigen Tagen die Monarchie im Reich beseitigte. Zudem waren sie überzeugt, im Sinne der neuen Regierung zu handeln, die Friedensverhandlungen mit der Entente anstrebte. Deren Glaubwürdigkeit hätte ein gleichzeitiger Angriff der Flotte zunichtegemacht. Vielmehr bezeichnete er das Vorhaben der Admiralität als „eine Meuterei der Flottenführung gegen die Regierung und ihre Politik“. Der Matrosenaufstand begann auf Schillig-Reede vor Wilhelmshaven, wo die deutsche Hochseeflotte in Erwartung der geplanten Seeschlacht vor Anker gegangen war. Auf drei Schiffen des III. Geschwaders weigerten sich die Matrosen, die Anker zu lichten. Auf den Schlachtschiffen des I. Geschwaders Thüringen und Helgoland gingen Teile der Besatzungen zu offener Meuterei und Sabotageakten über. Als aber am 31. Oktober einige Torpedoboote ihre Geschütze auf diese Schiffe richteten, verschanzten sich rund 200 Meuterer zunächst unter Deck, ließen sich dann aber widerstandslos verhaften. Da die Marineleitung sich des Gehorsams der Mannschaften nicht mehr sicher war, ließ sie ihren Schlachtplan fallen und beorderte das Geschwader nach Kiel zurück. Nachdem die Polizei das Gewerkschaftshaus für den 2. November gesperrt hatte, versammelten sich am Folgetag mehrere tausend Matrosen und Vertreter der Arbeiter nachmittags auf dem Großen Exerzierplatz. Sie kehrten entweder um oder schlossen sich der Aufstandsbewegung an.","Die Niederlage Deutschlands stand bereits fest. Trotzdem hatte er vor, die Flotte in eine letzte Schlacht gegen die Briten zu entsenden. Der Widerstand der SPD-Führung verhinderte Ziele des linken Flügels der Revolutionäre umzusetzen. Diese Ziele waren rätedemokratische Ideen, die über die Parlamentsarisierung hinaus gegangen wären. Am 24. Oktober 1918 brach durch den Flottenbefehl eine Meuterei unter den Matrosen aus. Die Meuterei wurde später zu einer Revolution, die in wenigen Tagen die Monarchie beseitigte. Sie waren außerdem überzeugt im Sinne der neuen Regierung zu handeln. Diese strebte Friedensverhandlungen mit der Entente an. Das waren die Länder, die am Ersten Weltkrieg beteiligt waren. Ein Angriff der Flotte zu diesem Zeitpunkt hätte die Friedensverhandlungen sehr beeinträchtigt. Er sagte, die Entscheidungen der Admirale seien ""eine Meuterei der Flottenführung gegen die Regierung und ihre Politik"". Der Matrosenaufstand begann vor Wilhelmshaven, auf Schilling-Reede. Dort lag die deutsche Hochseeflotte vor Anker und erwartete die Geplante Seeschlacht. Auf drei Schiffen, die zu einem Verband von Kriegsschiffen gehörten, weigerten sich die Schiffsleute weiterzufahren. Auf den Schlachtschiffen des ersten Geschwaders Thüringen ging ein Teil der Besatzung dazu über sich gegen den Kapitän zu stellen und zu meutern. Darüber hinaus beschädigten sie das Schiff absichtlich und machten es für den Einsatz untauglich. Das gleiche taten Teile der Matrosen des ersten Geschwaders Helgoland. 200 Meuterer versteckten sich unter Deck, als am 31. Oktober einige Boote ihre Torpedos auf die Schiffe richteten. Die Meuterer ließen sich aber später ohne Widerstand verhaften. Die Marineleitung war sich nicht mehr sicher, dass die Mannschaft ihr gehorchte. Deshalb ließ sie ihren Schlachtplan fallen und bestellte die Schiffe nach Kiel zurück. Die Polizei sperrte für den 2. November das Gewerkschaftshaus. Am Tage darauf versammelten sich mehrere tausend Matrosen und Vertreter der Arbeiter auf dem Großen Exerzierplatz.  Einige kehrten um. Andere schlossen sich den aufständischen Männern an."
20,20,20,20,20,228,21,Europäisches Parlament,"Seit der Gründung des Parlaments 1952 wurden seine Kompetenzen bei der EU-Rechtsetzung mehrmals deutlich erweitert, vor allem durch den Vertrag von Maastricht 1992 und zuletzt durch den Vertrag von Lissabon 2007, der am 1. Dezember 2009 in Kraft trat. Anders als in den meisten nationalen Parlamenten, wo die Regierungsfraktionen normalerweise loyal zur Regierung stehen und deren Gesetzentwürfe prinzipiell unterstützen, bilden sich im Europäischen Parlament je nach Abstimmungsthema wechselnde Mehrheiten. Dies bewirkt auch, dass die einzelnen Europa-Abgeordneten unabhängiger sind und mit Verhandlungsgeschick und Sachkenntnis größeren Einfluss auf die EU-Gesetzgebung haben, als es Abgeordneten nationaler Parlamente möglich ist. Das Bundesverfassungsgericht spricht dem Europäischen Parlament in seinem Urteil zum Lissabon-Vertrag vom 30. Juni 2009 nur eine eingeschränkte demokratische Legitimation zu und sieht seine Entscheidungskompetenzen bezüglich weiterer Schritte einer europäischen Integration dadurch begrenzt. In ihren Heimatländern sind diese Abgeordneten Mitglieder in rund 160 verschiedenen nationalen Parteien, die sich auf europäischer Ebene großenteils zu Europaparteien zusammengeschlossen haben. Demzufolge wird das Parlament gemeinsam mit dem Rat als Gesetzgeber tätig, übt gemeinsam mit ihm die Haushaltsbefugnisse aus und nimmt die politische Kontrolle wahr. Auch um den hohen Zeitaufwand dieses Verfahrens zu umgehen, werden jedoch immer mehr Gesetzesvorschläge in informellen Trilogverfahren verhandelt, um dann bereits in erster Lesung beschlossen werden zu können: zwischen 2004 und 2009 etwa traf dies auf 72 % aller Gesetzesentwürfe zu, im Vergleich zu 33 % zwischen 1999 und 2004. In einer verbindlichen Erklärung aus dem Jahr 2010 haben sich die Parlamentarier mit der Kommission geeinigt, den geltenden europarechtlichen Vorschriften eine Interpretationshilfe zu geben, sodass in Zukunft auf Anstoß des Parlamentes die Kommission innerhalb von zwölf Monaten einen Gesetzentwurf vorlegen oder innerhalb von drei Monaten detailliert begründen muss, warum sie es nicht macht. Neben dem ordentlichen Gesetzgebungsverfahren gibt es noch andere Formen der Rechtsetzung in der EU, bei denen das Parlament weniger Mitspracherechte besitzt. Dezember 2009 besitzt das Europäische Parlament im Bereich der Gemeinsamen Handelspolitik das Recht, Abänderungsvorschläge zu Gesetzesentwürfen einzubringen sowie auf Ablehnung des jeweiligen Rechtsaktes.","Seit der Gründung des Parlaments 1952 wurden seine Zuständigkeiten bei der EU-Rechtsetzung mehrmals deutlich erweitert. Der Vertrag von Maastricht 1992 und der Vertrag von Lissabon 2007 waren dafür wichtig. Der Vertrag von Lissabon trat am 1. Dezember 2009 in Kraft. In den meisten nationalen Parlamenten stehen die Regierungsfraktionen (Gruppen innerhalb der Regierung) normalerweise der Regierung treu. Sie unterstützen die Gesetzesentwürfe der Regierung. Aber im Europäischen Parlament bilden sich je nach Abstimmungsthema unterschiedliche Mehrheiten. Dies bewirkt auch, dass die einzelnen Europa-Abgeordneten unabhängiger sind. Außerdem haben sie mit guter Verhandlung und gutem Sach-Wissen größeren Einfluss auf die EU-Gesetzgebung. Mehr als Abgeordnete in nationalen Parlamenten. Das Bundesverfassungsgericht berechtigt das Europäische Parlament in seinem Urteil zum Lissabon-Vertrag (30. Juni 2009) nur zu wenigem. Dadurch sieht das Gericht die Entscheidungsfähigkeit des Parlamentes für die europäische Integration als begrenzt. In ihren Heimatländern sind diese Abgeordneten Mitglieder in rund 160 verschiedenen nationalen Parteien. Diese haben sich auf europäischer Ebene überwiegend zu Europa-Parteien zusammengeschlossen.  Das Europäische Parlament und der Rat sind als Gesetzgeber tätig. Gemeinsamen üben sie Haushalt-Befugnisse aus. Sie nehmen zudem die politische Kontrolle wahr. Auch weil dieses Verfahren sehr lange dauert, werden immer mehr Gesetzesvorschläge in informellen Trilogverfahren verhandelt. Das wird gemacht, damit sie bereits in der ersten Lesung beschlossen werden können. Zwischen 2004 und 2009 etwa traf dies auf 72% aller Gesetzesentwürfe zu. Zwischen 1999 und 2004 waren es nur 33%. 2010 hat sich das Europaparlament mit der Europäischen Kommission geeinigt: Wenn das Parlament ein Gesetz will, muss die Kommission innerhalb eines Jahres einen Entwurf machen. Wenn sie ein solches Gesetz nicht will, muss sie innerhalb von drei Monaten genau sagen, warum nicht. Auch bei anderen Arten der Gesetzgebung hat das Parlament weniger Mitspracherechte.  Seit dem 1.Dezember 2009 besitzt das Europäische Parlament in der gemeinsamen Handels-Politik das Recht, Vorschläge zur Änderung von Gesetzesentwürfen einzubringen. Außerdem kann das Parlament den jeweiligen Rechtsakt ablehnen."
21,21,21,21,21,238,22,Geschichte der Europäischen Union,"Die Geschichte der Europäischen Union ist durch ein Geflecht konkurrierender Motive und Entwicklungstendenzen charakterisiert, die zu unterschiedlichen Zeitpunkten jeweils richtungsgebend auf die Entwicklung der Gemeinschaft eingewirkt haben. Die Ausgestaltung und Fortführung des europäischen Integrationsprozesses bleibt auch unter den Bedingungen des Reformvertrags von Lissabon eine außerordentliche Bewährungsprobe. Ihrem Vorschlag gemäß sollten Umweltpolitik, Einwanderung und Asylrecht, Gesundheit und Drogenbekämpfung vergemeinschaftet werden, eine europäische Staatsbürgerschaft eingeführt und eine Gemeinsame Außen- und Sicherheitspolitik (GASP) auf den Weg gebracht werden. Erst nachdem die Dänen infolge Berücksichtigung gewisser Sonderinteressen (u.a. Nichtbeteiligung an der Währungsunion) in einer zweiten Volksabstimmung den Maastrichter Vertrag hatten passieren lassen und das deutsche Bundesverfassungsgericht Klagen gegen die Übertragung von Souveränitätsrechten auf die EU als – im gegebenen Rahmen – grundgesetzkonform zurückgewiesen hatte, konnte er zum 1. November 1993 in Kraft treten. Bald danach – zum 1. Januar 1995 – traten mit Österreich, Schweden und Finnland nach zügigen Beitrittsverhandlungen drei Staaten der EU bei, die bis zum Ende der Ost-West-Konfrontation durch ihre strikte Neutralitätspolitik daran gehindert waren. Mehr als die erst bei wenigen ins Bewusstsein gedrungene Unionsbürgerschaft hat – bereits vor dem Euro – der Abbau der Grenzkontrollen und Grenzanlagen zwischen den Bürgern der am Schengener Abkommen beteiligten Mitgliedstaaten ein Gefühl europäischer Zusammengehörigkeit wecken können. Die als Bestandteil des Binnenmarkts in der Einheitlichen Europäischen Akte festgeschriebene Freizügigkeit des Personenverkehrs wurde durch das 1985 in Schengen getroffene Abkommen zunächst von den Beneluxstaaten, Frankreich und der Bundesrepublik Deutschland auf den Weg gebracht, ohne dass aber die dazu nötige polizeiliche Zusammenarbeit und Vereinheitlichung der Visa die Durchführung schon gestattet hätte. Kohl war es, der Mitte 1988 Jacques Delors für die Projektleitung vorgeschlagen hatte; dieser wiederum hatte die Mitwirkung der Chefs der europäischen Zentralbanken an der Entwicklung entsprechender Pläne durchgesetzt, um den geballten Sachverstand der je obersten Währungshüter gegen zu erwartende Widerstände einzelner Regierungen ins Feld führen zu können.","Die Geschichte der Europäischen Union ist durch große Unterschiede von Motiven und Entwicklungen gekennzeichnet. Zu unterschiedlichen Zeitpunkten haben diese Unterschiede auf die Entwicklung der Gesellschaft Einfluss gehabt. Auch mit dem Reformvertrag von Lissabon bleibt die Zusammenarbeit der europäischen Länder kompliziert. Laut ihrem Vorschlag sollen die Umweltpolitik, Einwanderung und Asylrecht, Gesundheit und Drogenbekämpfung vergemeinschaftet werden. Außerdem soll eine europäische Staatsbürgerschaft eingeführt werden und eine gemeinsame Außen- und Sicherheitspolitik (GASP) gegründet werden. Der Maastrichter Vertrag konnte zum 1. November 1993 eingeführt werden. Aber erst nach dem die Dänen ihn in einer zweiten Volksabstimmung passieren ließen. Außerdem musste das deutsche Verfassungsgericht Klagen gegen den Vertrag ablehnen. Zum 1. Januar 1995 traten Österreich, Schweden und Finnland in die EU ein. Die Beitrittsverhandlungen dauerten nicht lange. Vor dem Ende der Ost-West-Konfrontation konnten sie nicht in die EU eintreten, weil ihre Politik neutral war. Der Abbau der Grenzkontrollen und Grenzanlagen hat zwischen den Bürgern der Mitgliedsstaaten vom Schengener Abkommen ein Gefühl europäischer Zusammengehörigkeit wecken können.  Teil der Schengener Abkommens war die Freizügigkeit des Personenverkehrs. Sie wurde 1985 zunächst von den Beneluxstaaten, Frankreich und Deutschland durchgesetzt. Allerdings ohne vorher auf Erlaubnis zu warten zur polizeilichen Zusammenarbeit und Vereinheitlichung der Visa. Im Jahr 1988 schlug der deutsche Bundeskanzler Helmut Kohl den Franzosen Jaques Delors für die Projektleitung vor. Delors erreichte, dass sich die Chefs der europäischen Zentralbanken an der Planung beteiligten. Weil er mit dem Widerstand einzelner Regierungen gegen die geplante Union rechnete, wollte er die Unterstützung wichtiger Finanzexperten haben."
22,22,22,22,22,246,23,Martin Luther King,"Wesentlich durch Kings Einsatz und Wirkkraft ist das Civil Rights Movement zu einer Massenbewegung geworden, die schließlich erreicht hat, dass die Rassentrennung gesetzlich aufgehoben und das uneingeschränkte Wahlrecht für die schwarze Bevölkerung der US-Südstaaten eingeführt wurde. Der Vater änderte beide Namen nach einer Europareise im Jahre 1934, die ihn im Zusammenhang mit dem in Berlin stattfindenden baptistischen Weltkongress auch nach Deutschland führte, zu Ehren von Martin Luther, für den er große Bewunderung empfand. Am 20. September 1944 begann King sein Studium am Morehouse College, der einzigen Hochschule für Schwarze im Süden; es nahm ihn trotz seines Alters von noch nicht 16 Jahren als Ausnahme auf. Im Hauptfach Soziologie wurde er von Walter P. Chivers in die Problematik der Rassentrennung eingeführt; bei George D. Kelsey, dem Leiter der „School of Religion“, hörte er von Mahatma Gandhis gewaltfreiem Widerstand.","Das Civil Rights Movement ist durch den Einsatz von King zu einer Massenbewegung geworden. Sie erreichte, dass die Rassentrennung gesetzlich aufgehoben wurde. Außerdem wurde das uneingeschränkte Wahlrecht für die schwarze Bevölkerung der US-Südstaaten eingeführt. Der Vater änderte beide Namen nach einer Europareise in 1934, weil er Martin Luther sehr bewunderte. In der Europareise war er beim baptistischen Weltkongress in Deutschland. Am 20. September 1944 begann King sein Studium am Morehouse College. Das war die einzige Hochschule im Süden, die auch Schwarze aufnahm. Obwohl King noch nicht mal 16 Jahre alt war, wurde er hier aufgenommen.  Sein Hauptfach war Soziologie. In die Problematik der Rassentrennuung führte ihn Walter C. Chievers ein. Bei dem Leiter der ""School of Religion"" George D. Kelsey hörte er von Mahatma Gandhis gewaltfreiem Widerstand."
